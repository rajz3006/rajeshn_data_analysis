{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline Route Analysis\n",
    "\n",
    "**Vision:** To develop a data-driven product that identifies and recommends the most promising U.S. domestic round-trip routes for a new airline venture. This product will prioritize profitability, operational efficiency (punctuality), and strategic market entry, enabling informed investment decisions. It will also incorporate a robust data quality monitoring framework.\n",
    "\n",
    "**Core User:** Airline leadership, route planning strategists, operations management, and data governance teams.\n",
    "\n",
    "**Key Objectives:**\n",
    " 1. Identify the 10 busiest round-trip routes (by flight volume).\n",
    " 2. Identify the 10 most profitable round-trip routes (pre-airplane cost), detailing revenue, cost, and key operational metrics.\n",
    " 3. Recommend 5 specific round-trip routes for investment, with clear justification.\n",
    " 4. Calculate the breakeven point (in terms of round-trip flights) for the $90 million airplane cost for each recommended route.\n",
    " 5. Propose Key Performance Indicators (KPIs) for monitoring the success of the chosen routes.\n",
    " 6. Implement a system for tracking and visualizing data quality metrics throughout the data processing pipeline.\n",
    "\n",
    " **Phases**\n",
    "1. Data Foundation\n",
    "    - Data Loading and Initial understanding\n",
    "    - Data Cleaning and Quality Assurance\n",
    "    - Data Transformation and Feature Engineering\n",
    "2. Analytical Insights & Visualization\n",
    "    - 10 Busiest Round-Trip Routes\n",
    "    - 10 Most Profitable Round-Trip Routes\n",
    "    - Route Recommendation\n",
    "    - Breakeven Analysis\n",
    "    - Tableau Reporting for Business\n",
    "3. Reporting & Strategic Outlook\n",
    "    - Future KPIs to track\n",
    "    - Future Roadmap\n",
    "\n",
    "All analytical steps have been supported by functions in the `airline_scripts` package, and data quality has been a consistent focus, with metrics logged via `dq_utils`. The outputs, including data tables, visualizations, and interpretations, are presented throughout this notebook. Data has also been prepared for potential use in Tableau dashboards.\n",
    "\n",
    "## Project Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ydata-profiling ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rajz/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <ins><a href=\"https://ydata.ai/register\">Upgrade to ydata-sdk</a></ins>\n",
       "                <p>\n",
       "                    Improve your data and profiling with ydata-sdk, featuring data quality scoring, redundancy detection, outlier identification, text validation, and synthetic data generation.\n",
       "                </p>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airline_scripts package initialized.\n",
      "config.py loaded with Coordinate column definitions and updated metadata.\n",
      "Libraries imported and project setup configured.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "# Ensure ydata-profiling is installed if you uncomment the profiling sections\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Import custom airline scripts\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Now import from airline_scripts\n",
    "from airline_scripts import config\n",
    "from airline_scripts import load_utils\n",
    "from airline_scripts import clean_utils\n",
    "from airline_scripts import feature_engineering_utils\n",
    "from airline_scripts import analysis_utils\n",
    "from airline_scripts import dq_utils\n",
    "\n",
    "# Configure pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "print(\"Libraries imported and project setup configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Data Foundation\n",
    "This phase focuses on loading the data, performing initial understanding, cleaning the data, ensuring quality, and then transforming it for analysis. Data quality metrics will be logged throughout this process.\n",
    "\n",
    "### Task 1.1: Data Loading & Initial Understanding\n",
    "\n",
    " - Load Flights, Tickets, and Airport Codes datasets using `load_utils.py`.\n",
    " - Log initial DQ metrics for each loaded dataset.\n",
    " - Perform initial data profiling (e.g., .head(), .info(), ydata-profiling).\n",
    " - Document initial hypotheses and observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DQ Log for Run ID: 49ec5f94-94e7-4896-94ba-67fc53ec3155\n",
      "DQ Log initialized. Ready to log metrics for Run ID: 49ec5f94-94e7-4896-94ba-67fc53ec3155.\n",
      "DQ Log initialized for Run ID: 49ec5f94-94e7-4896-94ba-67fc53ec3155\n",
      "Loading datasets...\n",
      "--- Starting Data Loading Phase (Loading ALL columns for profiling) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/airline_scripts/load_utils.py:21: DtypeWarning: Columns (3,13,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded all columns for Flights_Raw_Full from /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/data/Flights.csv. Shape: (1915886, 16)\n",
      "Successfully loaded all columns for Tickets_Raw_Full from /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/data/Tickets.csv. Shape: (1167285, 12)\n",
      "Successfully loaded all columns for Airport_Codes_Raw_Full from /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/data/Airport_Codes.csv. Shape: (55369, 8)\n",
      "--- Data Loading Phase Complete (All columns loaded) ---\n",
      "Flights_raw_df loaded with shape: (1915886, 16)\n",
      "Tickets_raw_df loaded with shape: (1167285, 12)\n",
      "Airport_codes_raw_df loaded with shape: (55369, 8)\n"
     ]
    }
   ],
   "source": [
    "# Initialize DQ Log for the run\n",
    "# This creates a new RunID and resets the in-memory DQ log DataFrame.\n",
    "dq_utils.initialize_dq_log()\n",
    "print(f\"DQ Log initialized for Run ID: {dq_utils.current_run_id}\")\n",
    "\n",
    "# %%\n",
    "# Load datasets using load_utils\n",
    "# These functions will use paths from config.py and log initial DQ metrics.\n",
    "print(\"Loading datasets...\")\n",
    "flights_raw_df, tickets_raw_df, airport_codes_raw_df = load_utils.load_all_data()\n",
    "\n",
    "# Check if data loading was successful by inspecting the shapes or if they are None\n",
    "if flights_raw_df is not None:\n",
    "    print(f\"Flights_raw_df loaded with shape: {flights_raw_df.shape}\")\n",
    "else:\n",
    "    print(\"Failed to load Flights_raw_df. Check config.FLIGHTS_FILE path and file existence.\")\n",
    "\n",
    "if tickets_raw_df is not None:\n",
    "    print(f\"Tickets_raw_df loaded with shape: {tickets_raw_df.shape}\")\n",
    "else:\n",
    "    print(\"Failed to load Tickets_raw_df. Check config.TICKETS_FILE path and file existence.\")\n",
    "\n",
    "if airport_codes_raw_df is not None:\n",
    "    print(f\"Airport_codes_raw_df loaded with shape: {airport_codes_raw_df.shape}\")\n",
    "else:\n",
    "    print(\"Failed to load Airport_codes_raw_df. Check config.AIRPORT_CODES_FILE path and file existence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Flights Data - Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Flights Raw Data ---\n",
      "Head:\n",
      "      FL_DATE OP_CARRIER TAIL_NUM OP_CARRIER_FL_NUM  ORIGIN_AIRPORT_ID ORIGIN  \\\n",
      "0  2019-03-02         WN   N955WN              4591              14635    RSW   \n",
      "1  2019-03-02         WN   N8686A              3231              14635    RSW   \n",
      "2  2019-03-02         WN   N201LV              3383              14635    RSW   \n",
      "3  2019-03-02         WN   N413WN              5498              14635    RSW   \n",
      "4  2019-03-02         WN   N7832A              6933              14635    RSW   \n",
      "\n",
      "  ORIGIN_CITY_NAME  DEST_AIRPORT_ID DESTINATION DEST_CITY_NAME  DEP_DELAY  \\\n",
      "0   Fort Myers, FL            11042         CLE  Cleveland, OH      -8.00   \n",
      "1   Fort Myers, FL            11066         CMH   Columbus, OH       1.00   \n",
      "2   Fort Myers, FL            11066         CMH   Columbus, OH       0.00   \n",
      "3   Fort Myers, FL            11066         CMH   Columbus, OH      11.00   \n",
      "4   Fort Myers, FL            11259         DAL     Dallas, TX       0.00   \n",
      "\n",
      "   ARR_DELAY  CANCELLED AIR_TIME DISTANCE  OCCUPANCY_RATE  \n",
      "0      -6.00       0.00   143.00  1025.00            0.97  \n",
      "1       5.00       0.00   135.00   930.00            0.55  \n",
      "2       4.00       0.00   132.00   930.00            0.91  \n",
      "3      14.00       0.00   136.00   930.00            0.67  \n",
      "4     -17.00       0.00   151.00  1005.00            0.62  \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1915886 entries, 0 to 1915885\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   FL_DATE            object \n",
      " 1   OP_CARRIER         object \n",
      " 2   TAIL_NUM           object \n",
      " 3   OP_CARRIER_FL_NUM  object \n",
      " 4   ORIGIN_AIRPORT_ID  int64  \n",
      " 5   ORIGIN             object \n",
      " 6   ORIGIN_CITY_NAME   object \n",
      " 7   DEST_AIRPORT_ID    int64  \n",
      " 8   DESTINATION        object \n",
      " 9   DEST_CITY_NAME     object \n",
      " 10  DEP_DELAY          float64\n",
      " 11  ARR_DELAY          float64\n",
      " 12  CANCELLED          float64\n",
      " 13  AIR_TIME           object \n",
      " 14  DISTANCE           object \n",
      " 15  OCCUPANCY_RATE     float64\n",
      "dtypes: float64(4), int64(2), object(10)\n",
      "memory usage: 233.9+ MB\n",
      "\n",
      "Describe:\n",
      "           FL_DATE OP_CARRIER TAIL_NUM  OP_CARRIER_FL_NUM  ORIGIN_AIRPORT_ID  \\\n",
      "count      1915886    1915886  1903730         1915886.00         1915886.00   \n",
      "unique         134         26     6032            9086.00                NaN   \n",
      "top     2019-03-15         WN   N485HA             403.00                NaN   \n",
      "freq         23361     330295      928             862.00                NaN   \n",
      "mean           NaN        NaN      NaN                NaN           12688.15   \n",
      "std            NaN        NaN      NaN                NaN            1521.90   \n",
      "min            NaN        NaN      NaN                NaN           10135.00   \n",
      "25%            NaN        NaN      NaN                NaN           11292.00   \n",
      "50%            NaN        NaN      NaN                NaN           12889.00   \n",
      "75%            NaN        NaN      NaN                NaN           14057.00   \n",
      "max            NaN        NaN      NaN                NaN           16218.00   \n",
      "\n",
      "         ORIGIN ORIGIN_CITY_NAME  DEST_AIRPORT_ID DESTINATION DEST_CITY_NAME  \\\n",
      "count   1915886          1915886       1915886.00     1915886        1915886   \n",
      "unique      361              355              NaN         361            355   \n",
      "top         ATL      Chicago, IL              NaN         ATL    Chicago, IL   \n",
      "freq      93763           111550              NaN       93635         112641   \n",
      "mean        NaN              NaN         12689.27         NaN            NaN   \n",
      "std         NaN              NaN          1521.25         NaN            NaN   \n",
      "min         NaN              NaN         10135.00         NaN            NaN   \n",
      "25%         NaN              NaN         11292.00         NaN            NaN   \n",
      "50%         NaN              NaN         12889.00         NaN            NaN   \n",
      "75%         NaN              NaN         14057.00         NaN            NaN   \n",
      "max         NaN              NaN         16218.00         NaN            NaN   \n",
      "\n",
      "        DEP_DELAY  ARR_DELAY  CANCELLED   AIR_TIME   DISTANCE  OCCUPANCY_RATE  \n",
      "count  1865535.00 1859895.00 1915886.00 1859335.00 1915256.00      1915576.00  \n",
      "unique        NaN        NaN        NaN    1208.00    1956.00             NaN  \n",
      "top           NaN        NaN        NaN      56.00     337.00             NaN  \n",
      "freq          NaN        NaN        NaN   16985.00   13490.00             NaN  \n",
      "mean        10.80       5.65       0.03        NaN        NaN            0.65  \n",
      "std         50.16      52.41       0.16        NaN        NaN            0.20  \n",
      "min        -63.00     -94.00       0.00        NaN        NaN            0.30  \n",
      "25%         -6.00     -15.00       0.00        NaN        NaN            0.48  \n",
      "50%         -2.00      -6.00       0.00        NaN        NaN            0.65  \n",
      "75%          7.00       8.00       0.00        NaN        NaN            0.82  \n",
      "max       2941.00    2923.00       1.00        NaN        NaN            1.00  \n"
     ]
    }
   ],
   "source": [
    "# Profiling Flights Data\n",
    "if flights_raw_df is not None:\n",
    "    print(\"\\n--- Flights Raw Data ---\")\n",
    "    print(\"Head:\")\n",
    "    print(flights_raw_df.head())\n",
    "    print(\"\\nInfo:\")\n",
    "    flights_raw_df.info()\n",
    "    print(\"\\nDescribe:\")\n",
    "    print(flights_raw_df.describe(include='all'))\n",
    "    # Generate ydata-profiling report (optional, can be time-consuming for large datasets)\n",
    "    # try:\n",
    "    #     print(f\"Generating profiling report for Flights data, saving to {config.PROFILING_REPORT_FLIGHTS}\")\n",
    "    #     profile_flights = ProfileReport(flights_raw_df, title=\"Flights Data Profiling Report\")\n",
    "    #     profile_flights.to_file(config.PROFILING_REPORT_FLIGHTS)\n",
    "    #     print(f\"Flights profiling report saved to {config.PROFILING_REPORT_FLIGHTS}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Could not generate ydata-profiling report for flights: {e}\")\n",
    "    #     print(\"Ensure 'ydata-profiling' is installed and the data directory/file paths in config.py are correct.\")\n",
    "else:\n",
    "    print(\"Flights data (flights_raw_df) is None, was not loaded correctly. Skipping profiling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Hypotheses or Observations:\n",
    " * Flights Data:\n",
    "     * `FL_DATE` should be converted to datetime format. Has only Q1 2019 Data\n",
    "     * `CANCELLED` - Convert to 'int' as is likely a binary indicator (0 or 1).\n",
    "     * `DISTANCE`, `AIR_TIME`, - Convert to Float\n",
    "     *  `DEP_DELAY`, `ARR_DELAY`, `AIR_TIME`, has close to 2.5% to 3% Missing values and outliers\n",
    "     *  `DISTANCE` Columns have values like 'Twenty', 'Hundred' , '****', ' ' etc. which needs to be cleaned.\n",
    "     * `OCCUPANCY_RATE` values are between 0.3 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tickets Data - Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tickets Raw Data ---\n",
      "Head:\n",
      "        ITIN_ID  YEAR  QUARTER ORIGIN ORIGIN_COUNTRY ORIGIN_STATE_ABR  \\\n",
      "0  201912723049  2019        1    ABI             US               TX   \n",
      "1  201912723085  2019        1    ABI             US               TX   \n",
      "2  201912723491  2019        1    ABI             US               TX   \n",
      "3  201912723428  2019        1    ABI             US               TX   \n",
      "4  201912723509  2019        1    ABI             US               TX   \n",
      "\n",
      "  ORIGIN_STATE_NM  ROUNDTRIP REPORTING_CARRIER  PASSENGERS ITIN_FARE  \\\n",
      "0           Texas       1.00                MQ        1.00     736.0   \n",
      "1           Texas       1.00                MQ        1.00     570.0   \n",
      "2           Texas       1.00                MQ        1.00     564.0   \n",
      "3           Texas       1.00                MQ        1.00     345.0   \n",
      "4           Texas       0.00                MQ        1.00     309.0   \n",
      "\n",
      "  DESTINATION  \n",
      "0         DAB  \n",
      "1         COS  \n",
      "2         MCO  \n",
      "3         LGA  \n",
      "4         MGM  \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1167285 entries, 0 to 1167284\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   ITIN_ID            1167285 non-null  int64  \n",
      " 1   YEAR               1167285 non-null  int64  \n",
      " 2   QUARTER            1167285 non-null  int64  \n",
      " 3   ORIGIN             1167285 non-null  object \n",
      " 4   ORIGIN_COUNTRY     1167285 non-null  object \n",
      " 5   ORIGIN_STATE_ABR   1167285 non-null  object \n",
      " 6   ORIGIN_STATE_NM    1167285 non-null  object \n",
      " 7   ROUNDTRIP          1167285 non-null  float64\n",
      " 8   REPORTING_CARRIER  1167285 non-null  object \n",
      " 9   PASSENGERS         1165308 non-null  float64\n",
      " 10  ITIN_FARE          1166325 non-null  object \n",
      " 11  DESTINATION        1167285 non-null  object \n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 106.9+ MB\n",
      "\n",
      "Describe:\n",
      "               ITIN_ID       YEAR    QUARTER   ORIGIN ORIGIN_COUNTRY  \\\n",
      "count       1167285.00 1167285.00 1167285.00  1167285        1167285   \n",
      "unique             NaN        NaN        NaN      419              1   \n",
      "top                NaN        NaN        NaN      LAX             US   \n",
      "freq               NaN        NaN        NaN    33462        1167285   \n",
      "mean   171560218178.93    2019.00       1.00      NaN            NaN   \n",
      "std     68349572156.60       0.00       0.00      NaN            NaN   \n",
      "min          201912.00    2019.00       1.00      NaN            NaN   \n",
      "25%    201911466844.00    2019.00       1.00      NaN            NaN   \n",
      "50%    201912800912.00    2019.00       1.00      NaN            NaN   \n",
      "75%    201913965014.00    2019.00       1.00      NaN            NaN   \n",
      "max    201915258097.00    2019.00       1.00      NaN            NaN   \n",
      "\n",
      "       ORIGIN_STATE_ABR ORIGIN_STATE_NM  ROUNDTRIP REPORTING_CARRIER  \\\n",
      "count           1167285         1167285 1167285.00           1167285   \n",
      "unique               52              52        NaN                21   \n",
      "top                  CA      California        NaN                AA   \n",
      "freq             129910          129910        NaN            185117   \n",
      "mean                NaN             NaN       0.61               NaN   \n",
      "std                 NaN             NaN       0.49               NaN   \n",
      "min                 NaN             NaN       0.00               NaN   \n",
      "25%                 NaN             NaN       0.00               NaN   \n",
      "50%                 NaN             NaN       1.00               NaN   \n",
      "75%                 NaN             NaN       1.00               NaN   \n",
      "max                 NaN             NaN       1.00               NaN   \n",
      "\n",
      "        PASSENGERS ITIN_FARE DESTINATION  \n",
      "count   1165308.00   1166325     1167285  \n",
      "unique         NaN      3791         410  \n",
      "top            NaN      11.0         LAX  \n",
      "freq           NaN     32926       38947  \n",
      "mean          2.07       NaN         NaN  \n",
      "std           5.84       NaN         NaN  \n",
      "min           1.00       NaN         NaN  \n",
      "25%           1.00       NaN         NaN  \n",
      "50%           1.00       NaN         NaN  \n",
      "75%           1.00       NaN         NaN  \n",
      "max         769.00       NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Profiling Tickets Data\n",
    "if tickets_raw_df is not None:\n",
    "    print(\"\\n--- Tickets Raw Data ---\")\n",
    "    print(\"Head:\")\n",
    "    print(tickets_raw_df.head())\n",
    "    print(\"\\nInfo:\")\n",
    "    tickets_raw_df.info()\n",
    "    print(\"\\nDescribe:\")\n",
    "    print(tickets_raw_df.describe(include='all'))\n",
    "    # Generate ydata-profiling report\n",
    "    # try:\n",
    "    #     print(f\"Generating profiling report for Tickets data, saving to {config.PROFILING_REPORT_TICKETS}\")\n",
    "    #     profile_tickets = ProfileReport(tickets_raw_df, title=\"Tickets Data Profiling Report\")\n",
    "    #     profile_tickets.to_file(config.PROFILING_REPORT_TICKETS)\n",
    "    #     print(f\"Tickets profiling report saved to {config.PROFILING_REPORT_TICKETS}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Could not generate ydata-profiling report for tickets: {e}\")\n",
    "else:\n",
    "    print(\"Tickets data (tickets_raw_df) is None, was not loaded correctly. Skipping profiling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Hypotheses and Observations:\n",
    " * Tickets Data:\n",
    "     * Analysis requires filtering for `ROUNDTRIP == 1` and data from `1Q2019` (`YEAR == 2019`, `QUARTER == 1`).\n",
    "     * `ITIN_FARE` is a crucial column for profitability analysis; its distribution and potential outliers will be important.\n",
    "     * This dataset is explicitly mentioned as \"sample data,\" so it might not provide fare information for all routes present in the Flights dataset. This could lead to challenges in the join process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Airport Codes Data - Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Airport Codes Raw Data ---\n",
      "Head:\n",
      "            TYPE                                NAME  ELEVATION_FT CONTINENT  \\\n",
      "0       heliport                   Total Rf Heliport         11.00       NaN   \n",
      "1  small_airport                Aero B Ranch Airport       3435.00       NaN   \n",
      "2  small_airport                        Lowell Field        450.00       NaN   \n",
      "3  small_airport                        Epps Airpark        820.00       NaN   \n",
      "4         closed  Newport Hospital & Clinic Heliport        237.00       NaN   \n",
      "\n",
      "  ISO_COUNTRY  MUNICIPALITY IATA_CODE                            COORDINATES  \n",
      "0          US      Bensalem       NaN     -74.93360137939453, 40.07080078125  \n",
      "1          US         Leoti       NaN                 -101.473911, 38.704022  \n",
      "2          US  Anchor Point       NaN            -151.695999146, 59.94919968  \n",
      "3          US       Harvest       NaN  -86.77030181884766, 34.86479949951172  \n",
      "4          US       Newport       NaN                    -91.254898, 35.6087  \n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55369 entries, 0 to 55368\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   TYPE          55369 non-null  object \n",
      " 1   NAME          55369 non-null  object \n",
      " 2   ELEVATION_FT  48354 non-null  float64\n",
      " 3   CONTINENT     27526 non-null  object \n",
      " 4   ISO_COUNTRY   55122 non-null  object \n",
      " 5   MUNICIPALITY  49663 non-null  object \n",
      " 6   IATA_CODE     9182 non-null   object \n",
      " 7   COORDINATES   55369 non-null  object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 3.4+ MB\n",
      "\n",
      "Describe:\n",
      "                 TYPE                         NAME  ELEVATION_FT CONTINENT  \\\n",
      "count           55369                        55369      48354.00     27526   \n",
      "unique              7                        52426           NaN         6   \n",
      "top     small_airport  Centre Hospitalier Heliport           NaN        EU   \n",
      "freq            34120                           85           NaN      7955   \n",
      "mean              NaN                          NaN       1245.49       NaN   \n",
      "std               NaN                          NaN       1608.48       NaN   \n",
      "min               NaN                          NaN      -1266.00       NaN   \n",
      "25%               NaN                          NaN        205.00       NaN   \n",
      "50%               NaN                          NaN        720.00       NaN   \n",
      "75%               NaN                          NaN       1500.00       NaN   \n",
      "max               NaN                          NaN      22000.00       NaN   \n",
      "\n",
      "       ISO_COUNTRY MUNICIPALITY IATA_CODE            COORDINATES  \n",
      "count        55122        49663      9182                  55369  \n",
      "unique         242        27221      9062                  55240  \n",
      "top             US        Seoul         0  129.115255, 37.540345  \n",
      "freq         22810          403        80                     50  \n",
      "mean           NaN          NaN       NaN                    NaN  \n",
      "std            NaN          NaN       NaN                    NaN  \n",
      "min            NaN          NaN       NaN                    NaN  \n",
      "25%            NaN          NaN       NaN                    NaN  \n",
      "50%            NaN          NaN       NaN                    NaN  \n",
      "75%            NaN          NaN       NaN                    NaN  \n",
      "max            NaN          NaN       NaN                    NaN  \n"
     ]
    }
   ],
   "source": [
    "# Profiling Airport Codes Data\n",
    "if airport_codes_raw_df is not None:\n",
    "    print(\"\\n--- Airport Codes Raw Data ---\")\n",
    "    print(\"Head:\")\n",
    "    print(airport_codes_raw_df.head())\n",
    "    print(\"\\nInfo:\")\n",
    "    airport_codes_raw_df.info()\n",
    "    print(\"\\nDescribe:\")\n",
    "    print(airport_codes_raw_df.describe(include='all'))\n",
    "    # Generate ydata-profiling report\n",
    "    # try:\n",
    "    #     print(f\"Generating profiling report for Airport Codes data, saving to {config.PROFILING_REPORT_AIRPORTS}\")\n",
    "    #     profile_airports = ProfileReport(airport_codes_raw_df, title=\"Airport Codes Data Profiling Report\")\n",
    "    #     profile_airports.to_file(config.PROFILING_REPORT_AIRPORTS)\n",
    "    #     print(f\"Airport codes profiling report saved to {config.PROFILING_REPORT_AIRPORTS}\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Could not generate ydata-profiling report for airport codes: {e}\")\n",
    "else:\n",
    "    print(\"Airport codes data (airport_codes_raw_df) is None, was not loaded correctly. Skipping profiling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Hypotheses and Observations:\n",
    " * Airport Codes Data:\n",
    "     * Filtering will be necessary for `ISO_COUNTRY == 'US'` and `TYPE` in `['medium_airport', 'large_airport']`.\n",
    "     * `IATA_CODE` will serve as the primary key for joining with Flights and Tickets data. Uniqueness of `IATA_CODE` after filtering will be important.\n",
    "\n",
    " *General Observations:*\n",
    " * Data quality issues such as missing values, outliers, incorrect data types, and inconsistencies are expected and will be addressed systematically.\n",
    " * The join strategy between these datasets will be critical. Inner joins might lead to data loss if keys don't match perfectly (e.g., an airport in Flights not present in filtered Airport Codes, or a route in Flights not having sample fare data in Tickets).\n",
    " * The `dq_utils` module will be used to log metrics at each step, providing a traceable record of data transformations and quality checks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Task 1.2: Data Cleaning & Quality Assurance\n",
    " - For each significant cleaning step, log DQ metrics before and after the operation using `dq_utils`.\n",
    " - Use `clean_utils.py` for cleaning operations (handling missing values, data type conversions, filtering based on requirements).\n",
    " - Document all cleaning steps, rationale, and at least 3 data quality insights.\n",
    " - All the rejected records have to be captured in a seperate CSV files for further manual analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Cleaning Flights Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flights Data Cleaning:\n",
    "\n",
    "* Steps:\n",
    "    * Select Relevant Columns: Keeps only essential flight information columns (e.g., date, origin, destination, delays, distance, occupancy, cancellation status).\n",
    "    * Convert Data Types: Ensures dates are date objects, numerical fields (like distance, airtime, delays, occupancy) are numbers, and identifiers (like origin, destination) are strings. Unparseable values become 'missing'.\n",
    "    * Filter Cancelled Flights: Removes rows where the flight is marked as cancelled or its cancellation status is unclear/missing.\n",
    "    * Handle Missing/Unparseable Values:\n",
    "        * Imputes missing departure and arrival delays with 0.\n",
    "        * Filters out rows if other critical required columns (like flight date, airtime after type conversion) still have missing/unparseable values.\n",
    "    * Validate Occupancy Rate: Filters out rows where the occupancy rate is not between 0 and 1 (inclusive) or is missing.\n",
    "    * Handle Outliers: Applies the configured outlier handling (impute with mean, filter, or none) to DEP_DELAY, ARR_DELAY, AIR_TIME, and DISTANCE.\n",
    "    * Log & Save Rejects: All filtered rows are saved to rejected_flights_data.csv with reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Flights Data ---\n",
      "Step: Filtered Flights to required columns. Kept 10 columns.\n",
      "Excluded columns at cleaning start for Flights: ['OP_CARRIER', 'TAIL_NUM', 'ORIGIN_AIRPORT_ID', 'ORIGIN_CITY_NAME', 'DEST_AIRPORT_ID', 'DEST_CITY_NAME']\n",
      "Warning: Column 'FL_DATE' had 5050 value(s) result in NaN/NaT/NA during conversion to datetime64[ns].\n",
      "Warning: Column 'DISTANCE' had 2110 value(s) result in NaN/NaT/NA during conversion to float.\n",
      "Warning: Column 'AIR_TIME' had 1910 value(s) result in NaN/NaT/NA during conversion to float.\n",
      "Filtered out 51614 cancelled/unclear flights.\n",
      "\n",
      "--- Handling Missing/Unusual Values for Flights ---\n",
      "Filtered 4900 rows (NaNs in 'FL_DATE').\n",
      "Imputed 4367 NaNs in 'ARR_DELAY'.\n",
      "Filtered 4367 rows (NaNs in 'AIR_TIME').\n",
      "Total rows filtered (missing/unparseable) from Flights: 9267\n",
      "Detected 244571 outliers in 'DEP_DELAY'.\n",
      "Imputed 244571 outliers in 'DEP_DELAY' with mean: -1.52.\n",
      "Detected 174562 outliers in 'ARR_DELAY'.\n",
      "Imputed 174562 outliers in 'ARR_DELAY' with mean: -5.60.\n",
      "Detected 93850 outliers in 'AIR_TIME'.\n",
      "Imputed 93850 outliers in 'AIR_TIME' with mean: 98.49.\n",
      "Detected 98297 outliers in 'DISTANCE'.\n",
      "Imputed 98297 outliers in 'DISTANCE' with mean: 678.19.\n",
      "Saved 56336 unique rejected rows for Flights_Rejects to /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/logs/rejected_flights_data.csv\n",
      "Finished cleaning Flights data. Final shape: (1855005, 10)\n",
      "\n",
      "Cleaned Flights Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1855005 entries, 0 to 1910835\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Dtype         \n",
      "---  ------             -----         \n",
      " 0   FL_DATE            datetime64[ns]\n",
      " 1   OP_CARRIER_FL_NUM  object        \n",
      " 2   ORIGIN             object        \n",
      " 3   DESTINATION        object        \n",
      " 4   DEP_DELAY          Float64       \n",
      " 5   ARR_DELAY          Float64       \n",
      " 6   CANCELLED          int64         \n",
      " 7   AIR_TIME           Float64       \n",
      " 8   DISTANCE           Float64       \n",
      " 9   OCCUPANCY_RATE     Float64       \n",
      "dtypes: Float64(5), datetime64[ns](1), int64(1), object(3)\n",
      "memory usage: 164.5+ MB\n",
      "\n",
      "Shape of cleaned flights: (1855005, 10)\n",
      "Cancelled values in cleaned flights data: [0]\n",
      "Min/Max Occupancy Rate: 0.3 / 1.0\n",
      "Saved DataFrame to: /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/output_steps/flights_after_clean.csv\n"
     ]
    }
   ],
   "source": [
    "if flights_raw_df is not None:\n",
    "    print(\"\\n--- Cleaning Flights Data ---\")\n",
    "    # The clean_flights_data function handles missing values (dropping critical NAs, filling delay NAs),\n",
    "    # converts data types, filters out cancelled flights, and validates occupancy rate. DQ metrics are logged.\n",
    "    flights_cleaned_df = clean_utils.clean_flights_data(flights_raw_df.copy())\n",
    "    if flights_cleaned_df is not None and not flights_cleaned_df.empty:\n",
    "        print(\"\\nCleaned Flights Info:\")\n",
    "        flights_cleaned_df.info()\n",
    "        print(f\"\\nShape of cleaned flights: {flights_cleaned_df.shape}\")\n",
    "        # Verify filters\n",
    "        print(f\"Cancelled values in cleaned flights data: {flights_cleaned_df[config.COL_FL_CANCELLED].unique()}\") # Should be [0]\n",
    "        print(f\"Min/Max Occupancy Rate: {flights_cleaned_df[config.COL_FL_OCCUPANCY].min()} / {flights_cleaned_df[config.COL_FL_OCCUPANCY].max()}\")\n",
    "    elif flights_cleaned_df is not None and flights_cleaned_df.empty:\n",
    "        print(\"Flights data cleaning resulted in an empty DataFrame. Check filters (e.g., cancellation filter) and raw data.\")\n",
    "    else: # flights_cleaned_df is None\n",
    "        print(\"Flights data cleaning failed or returned None.\")\n",
    "else:\n",
    "    print(\"Flights raw data (flights_raw_df) is not available for cleaning.\")\n",
    "    flights_cleaned_df = pd.DataFrame()\n",
    "\n",
    "step_name = \"flights_after_clean\"\n",
    "file_name = f\"{step_name}.csv\"\n",
    "output_file_path = os.path.join(config.STEP_OUTPUT_DIR, file_name)\n",
    "batch_timestamp = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M\")\n",
    "\n",
    "flights_cleaned_df.loc[:, 'batch_id'] = batch_timestamp\n",
    "\n",
    "flights_cleaned_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Saved DataFrame to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Tickets Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Steps:\n",
    "    * Select Relevant Columns: Keeps only essential ticket information (e.g., year, quarter, origin, destination, roundtrip status, itinerary fare).\n",
    "    * Convert Data Types: Ensures numerical fields (like fare, year, quarter) are numbers and identifiers are strings. Unparseable values become 'missing'.\n",
    "    * Filter by Business Rules:\n",
    "        * Removes tickets that are not round trips (ROUNDTRIP != 1) or where roundtrip status is unclear/missing.\n",
    "        * Removes tickets not within the specified analysis period (1Q2019).\n",
    "    * Handle Missing/Unparseable Values: Filters out rows if any remaining required columns (like itinerary fare, origin, destination after type conversion) have missing/unparseable values.\n",
    "    * Validate Itinerary Fare: Filters out tickets with a non-positive (<=0) itinerary fare.\n",
    "    * Handle Outliers: Applies the configured outlier handling to ITIN_FARE.\n",
    "    * Log & Save Rejects: All filtered rows are saved to rejected_tickets_data.csv with reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Tickets Data ---\n",
      "Step: Filtered Tickets to required columns. Kept 7 columns.\n",
      "Excluded columns at cleaning start for Tickets: ['ITIN_ID', 'ORIGIN_COUNTRY', 'ORIGIN_STATE_ABR', 'ORIGIN_STATE_NM', 'REPORTING_CARRIER']\n",
      "Warning: Column 'ITIN_FARE' had 3176 value(s) result in NaN/NaT/NA during conversion to float.\n",
      "Filtered 458685 non-roundtrip tickets.\n",
      "Filtered 1197 rows (NaNs in 'PASSENGERS' for Tickets).\n",
      "Filtered 1842 rows (NaNs in 'ITIN_FARE' for Tickets).\n",
      "Total rows filtered (missing/unparseable) from Tickets: 3039\n",
      "Filtered 6370 tickets (non-positive fare).\n",
      "Detected 30846 outliers in 'ITIN_FARE'.\n",
      "Imputed 30846 outliers in 'ITIN_FARE' with mean: 430.08.\n",
      "Saved 414758 unique rejected rows for Tickets_Rejects to /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/logs/rejected_tickets_data.csv\n",
      "Finished cleaning Tickets data. Final shape: (699191, 7)\n",
      "\n",
      "Cleaned Tickets Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 699191 entries, 0 to 1167284\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   YEAR         699191 non-null  int64  \n",
      " 1   QUARTER      699191 non-null  int64  \n",
      " 2   ORIGIN       699191 non-null  object \n",
      " 3   ROUNDTRIP    699191 non-null  int64  \n",
      " 4   PASSENGERS   699191 non-null  Float64\n",
      " 5   ITIN_FARE    699191 non-null  Float64\n",
      " 6   DESTINATION  699191 non-null  object \n",
      "dtypes: Float64(2), int64(3), object(2)\n",
      "memory usage: 44.0+ MB\n",
      "\n",
      "Shape of cleaned tickets: (699191, 7)\n",
      "Years in cleaned tickets data: [2019]\n",
      "Quarters in cleaned tickets data: [1]\n",
      "Roundtrip values in cleaned tickets data: [1]\n",
      "Min ITIN_FARE in cleaned tickets: 1.0\n",
      "Saved DataFrame to: /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/output_steps/tickets_after_clean.csv\n"
     ]
    }
   ],
   "source": [
    "if tickets_raw_df is not None:\n",
    "    print(\"\\n--- Cleaning Tickets Data ---\")\n",
    "    # The clean_tickets_data function handles missing values, filters for 1Q2019 roundtrip tickets,\n",
    "    # converts data types, and filters non-positive fares. DQ metrics are logged within.\n",
    "    tickets_cleaned_df = clean_utils.clean_tickets_data(tickets_raw_df.copy())\n",
    "    if tickets_cleaned_df is not None and not tickets_cleaned_df.empty:\n",
    "        print(\"\\nCleaned Tickets Info:\")\n",
    "        tickets_cleaned_df.info()\n",
    "        print(f\"\\nShape of cleaned tickets: {tickets_cleaned_df.shape}\")\n",
    "        # Verify filters\n",
    "        print(f\"Years in cleaned tickets data: {tickets_cleaned_df[config.COL_TK_YEAR].unique()}\")\n",
    "        print(f\"Quarters in cleaned tickets data: {tickets_cleaned_df[config.COL_TK_QUARTER].unique()}\")\n",
    "        print(f\"Roundtrip values in cleaned tickets data: {tickets_cleaned_df[config.COL_TK_ROUNDTRIP].unique()}\")\n",
    "        print(f\"Min ITIN_FARE in cleaned tickets: {tickets_cleaned_df[config.COL_TK_ITIN_FARE].min()}\")\n",
    "    elif tickets_cleaned_df is not None and tickets_cleaned_df.empty:\n",
    "        print(\"Tickets data cleaning resulted in an empty DataFrame. This is possible if no 1Q2019 roundtrip tickets exist or all had issues.\")\n",
    "        print(\"Profitability analysis will be significantly impacted if ticket data is empty.\")\n",
    "    else: # tickets_cleaned_df is None\n",
    "        print(\"Tickets data cleaning failed or returned None.\")\n",
    "else:\n",
    "    print(\"Tickets raw data (tickets_raw_df) is not available for cleaning.\")\n",
    "    tickets_cleaned_df = pd.DataFrame()\n",
    "\n",
    "step_name = \"tickets_after_clean\"\n",
    "file_name = f\"{step_name}.csv\"\n",
    "output_file_path = os.path.join(config.STEP_OUTPUT_DIR, file_name)\n",
    "batch_timestamp = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M\")\n",
    "\n",
    "tickets_cleaned_df.loc[:, 'batch_id'] = batch_timestamp\n",
    "\n",
    "tickets_cleaned_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Saved DataFrame to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Airport Codes Data\n",
    "\n",
    "* Steps:\n",
    "    * Select Relevant Columns: Keeps essential airport information (IATA code, type, name, country, coordinates).\n",
    "    * Convert Data Types: Ensures key identifiers and filterable fields (like IATA code, type, country, coordinates) are treated as strings initially for reliable processing.\n",
    "    * Parse Coordinates: Splits the COORDINATES string into separate LATITUDE and LONGITUDE numeric columns. Rows with malformed or unparseable coordinates are filtered out.\n",
    "    * Handle Missing Critical Info: Filters out airports missing essential identifiers needed for subsequent filtering (IATA_CODE, TYPE, ISO_COUNTRY).\n",
    "    * Filter by Business Rules:\n",
    "        * Removes airports not in the 'US' (ISO_COUNTRY != 'US').\n",
    "        * Removes airports not classified as 'medium_airport' or 'large_airport'.\n",
    "        * Removes duplicate airport entries based on IATA_CODE, keeping only the first occurrence.\n",
    "    * Handle Remaining Missing Values: Filters out rows if any other required columns (like NAME, or the newly created LATITUDE/LONGITUDE) have missing values.\n",
    "    * Outlier Handling: Typically not applied to descriptive airport fields in this context.\n",
    "    * Log & Save Rejects: All filtered rows are saved to rejected_airports_data.csv with reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Airport Codes Data ---\n",
      "Step: Filtered Airport_Codes to required columns. Kept 5 columns.\n",
      "Excluded columns at cleaning start for Airport_Codes: ['ELEVATION_FT', 'CONTINENT', 'MUNICIPALITY']\n",
      "\n",
      "--- Parsing Coordinates for Airport_Codes ---\n",
      "Successfully parsed coordinates into LATITUDE and LONGITUDE.\n",
      "Filtered 32559 non-US airports.\n",
      "Filtered 21952 invalid airport types.\n",
      "Filtered 36 duplicate IATA airports.\n",
      "\n",
      "--- Handling Missing/Unusual Values for Airport_Codes (Remaining Columns) ---\n",
      "\n",
      "--- Outlier handling not applied to Airport_Codes descriptive fields ---\n",
      "Saved 54438 unique rejected rows for Airport_Codes_Rejects to /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/logs/rejected_airports_data.csv\n",
      "Finished cleaning Airport_Codes data. Final shape: (822, 7)\n",
      "\n",
      "Cleaned Airport Codes Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 822 entries, 6194 to 39286\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   IATA_CODE    822 non-null    object \n",
      " 1   TYPE         822 non-null    object \n",
      " 2   NAME         822 non-null    object \n",
      " 3   ISO_COUNTRY  822 non-null    object \n",
      " 4   COORDINATES  822 non-null    object \n",
      " 5   LONGITUDE    822 non-null    float64\n",
      " 6   LATITUDE     822 non-null    float64\n",
      "dtypes: float64(2), object(5)\n",
      "memory usage: 51.4+ KB\n",
      "\n",
      "Shape of cleaned airport codes: (822, 7)\n",
      "Unique IATA codes in cleaned data: 822\n",
      "Types of airports in cleaned data: ['medium_airport' 'large_airport']\n",
      "Countries in cleaned data: ['US']\n",
      "Saved DataFrame to: /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/output_steps/airports_after_clean.csv\n"
     ]
    }
   ],
   "source": [
    "if airport_codes_raw_df is not None:\n",
    "    print(\"\\n--- Cleaning Airport Codes Data ---\")\n",
    "    # The clean_airport_codes_data function handles missing values, filters for US medium/large airports,\n",
    "    # and checks for duplicate IATA codes. DQ metrics are logged within the function.\n",
    "    airport_codes_cleaned_df = clean_utils.clean_airport_codes_data(airport_codes_raw_df.copy()) # Use .copy() to avoid SettingWithCopyWarning on the raw df\n",
    "    if airport_codes_cleaned_df is not None and not airport_codes_cleaned_df.empty:\n",
    "        print(\"\\nCleaned Airport Codes Info:\")\n",
    "        airport_codes_cleaned_df.info()\n",
    "        print(f\"\\nShape of cleaned airport codes: {airport_codes_cleaned_df.shape}\")\n",
    "        print(f\"Unique IATA codes in cleaned data: {airport_codes_cleaned_df[config.COL_AIRPORT_IATA].nunique()}\")\n",
    "        print(f\"Types of airports in cleaned data: {airport_codes_cleaned_df[config.COL_AIRPORT_TYPE].unique()}\")\n",
    "        print(f\"Countries in cleaned data: {airport_codes_cleaned_df[config.COL_AIRPORT_ISO_COUNTRY].unique()}\")\n",
    "    elif airport_codes_cleaned_df is not None and airport_codes_cleaned_df.empty:\n",
    "        print(\"Airport codes cleaning resulted in an empty DataFrame. Check filters and raw data.\")\n",
    "    else: # airport_codes_cleaned_df is None\n",
    "        print(\"Airport codes cleaning failed or returned None.\")\n",
    "else:\n",
    "    print(\"Airport codes raw data (airport_codes_raw_df) is not available for cleaning.\")\n",
    "    airport_codes_cleaned_df = pd.DataFrame() # Ensure it's an empty DF to prevent errors later\n",
    "\n",
    "step_name = \"airports_after_clean\"\n",
    "file_name = f\"{step_name}.csv\"\n",
    "output_file_path = os.path.join(config.STEP_OUTPUT_DIR, file_name)\n",
    "batch_timestamp = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M\")\n",
    "\n",
    "airport_codes_cleaned_df.loc[:, 'batch_id'] = batch_timestamp\n",
    "\n",
    "airport_codes_cleaned_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Saved DataFrame to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3: Data Transformation & Feature Engineering\n",
    " - For key transformation steps (e.g., joins), log DQ metrics before and after operations using `dq_utils`.\n",
    " - Use `feature_engineering_utils.py` for transformations like creating route columns, joining datasets, and calculating detailed cost/revenue figures per flight.\n",
    " - Document metadata for newly engineered fields (this is primarily done via docstrings in `.py` files and `config.py`, and summarized here).\n",
    "\n",
    "* Steps:\n",
    "    * Initial Logging: Records the start of the feature engineering process.\n",
    "    * Create Route Identifiers: Generates ROUTE (Origin-Destination) and CANONICAL_ROUTE_PAIR (standardized round-trip) columns.\n",
    "    * Join Flights with Airport Details: Merges flight data with airport data (name, type, lat/lon) for both origin and destination.\n",
    "    * Join with Aggregated Ticket Data: Attaches average route fares (from sample ticket data) to flight records.\n",
    "    * Calculate Flight Costs: Computes various operational costs (fuel, airport, delay, etc.) for each flight leg.\n",
    "    * Calculate Flight Revenue: Estimates ticket and baggage revenue for each flight leg based on occupancy and fares.\n",
    "    * Calculate Profit (per leg): Determines operational profit for each flight leg by subtracting total costs from total revenue.\n",
    "    * Final ABT Creation & Logging: Consolidates all transformations into the Analytical Base Table and logs its final status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Feature Engineering ---\n",
      "--- Starting Feature Engineering Phase ---\n",
      "Flights after inner join with origin airports: 1838774 rows.\n",
      "Flights after inner join with destination airports: 1823296 rows.\n",
      "Joined with aggregated ticket data. 1804570 flights got fare, 18726 did not.\n",
      "--- Feature Engineering Phase Complete. ABT created with shape: (1823296, 35) ---\n",
      "\n",
      "--- Analytical Base Table (ABT) Created ---\n",
      "ABT Head:\n",
      "     FL_DATE OP_CARRIER_FL_NUM ORIGIN DESTINATION  DEP_DELAY  ARR_DELAY  \\\n",
      "0 2019-03-02              4591    RSW         CLE      -8.00      -6.00   \n",
      "1 2019-03-02              3231    RSW         CMH       1.00       5.00   \n",
      "2 2019-03-02              3383    RSW         CMH       0.00       4.00   \n",
      "3 2019-03-02              5498    RSW         CMH      11.00      14.00   \n",
      "4 2019-03-02              6933    RSW         DAL       0.00     -17.00   \n",
      "\n",
      "   CANCELLED  AIR_TIME  DISTANCE  OCCUPANCY_RATE          batch_id    ROUTE  \\\n",
      "0          0    143.00   1025.00            0.97  2025-05-13T21:40  RSW-CLE   \n",
      "1          0    135.00    930.00            0.55  2025-05-13T21:40  RSW-CMH   \n",
      "2          0    132.00    930.00            0.91  2025-05-13T21:40  RSW-CMH   \n",
      "3          0    136.00    930.00            0.67  2025-05-13T21:40  RSW-CMH   \n",
      "4          0    151.00   1005.00            0.62  2025-05-13T21:40  RSW-DAL   \n",
      "\n",
      "  CANONICAL_ROUTE_PAIR ORIGIN_AIRPORT_TYPE  \\\n",
      "0              CLE-RSW       large_airport   \n",
      "1              CMH-RSW       large_airport   \n",
      "2              CMH-RSW       large_airport   \n",
      "3              CMH-RSW       large_airport   \n",
      "4              DAL-RSW       large_airport   \n",
      "\n",
      "                       ORIGIN_AIRPORT_NAME  ORIGIN_LATITUDE  ORIGIN_LONGITUDE  \\\n",
      "0  Southwest Florida International Airport            26.54            -81.76   \n",
      "1  Southwest Florida International Airport            26.54            -81.76   \n",
      "2  Southwest Florida International Airport            26.54            -81.76   \n",
      "3  Southwest Florida International Airport            26.54            -81.76   \n",
      "4  Southwest Florida International Airport            26.54            -81.76   \n",
      "\n",
      "  DEST_AIRPORT_TYPE                          DEST_AIRPORT_NAME  DEST_LATITUDE  \\\n",
      "0     large_airport    Cleveland Hopkins International Airport          41.41   \n",
      "1     large_airport  John Glenn Columbus International Airport          40.00   \n",
      "2     large_airport  John Glenn Columbus International Airport          40.00   \n",
      "3     large_airport  John Glenn Columbus International Airport          40.00   \n",
      "4     large_airport                          Dallas Love Field          32.85   \n",
      "\n",
      "   DEST_LONGITUDE  AVG_ROUTE_ITIN_FARE  COST_FUEL_ETC  COST_DEPRECIATION_ETC  \\\n",
      "0          -81.85               214.94        8200.00                1209.50   \n",
      "1          -82.89               262.83        7440.00                1097.40   \n",
      "2          -82.89               262.83        7440.00                1097.40   \n",
      "3          -82.89               262.83        7440.00                1097.40   \n",
      "4          -96.85               405.55        8040.00                1185.90   \n",
      "\n",
      "   COST_AIRPORT_OPERATIONAL  DEP_DELAY_CHARGEABLE  COST_DEP_DELAY  \\\n",
      "0                     10000                  0.00            0.00   \n",
      "1                     10000                  0.00            0.00   \n",
      "2                     10000                  0.00            0.00   \n",
      "3                     10000                  0.00            0.00   \n",
      "4                     10000                  0.00            0.00   \n",
      "\n",
      "   ARR_DELAY_CHARGEABLE  COST_ARR_DELAY  TOTAL_FLIGHT_COST  \\\n",
      "0                  0.00            0.00           19409.50   \n",
      "1                  0.00            0.00           18537.40   \n",
      "2                  0.00            0.00           18537.40   \n",
      "3                  0.00            0.00           18537.40   \n",
      "4                  0.00            0.00           19225.90   \n",
      "\n",
      "   CALCULATED_PASSENGERS  TICKET_REVENUE_PER_LEG  BAGGAGE_REVENUE_PER_LEG  \\\n",
      "0                    194                20849.50                  3395.00   \n",
      "1                    110                14455.66                  1925.00   \n",
      "2                    182                23917.55                  3185.00   \n",
      "3                    134                17609.62                  2345.00   \n",
      "4                    124                25143.82                  2170.00   \n",
      "\n",
      "   TOTAL_FLIGHT_REVENUE  PROFIT_PER_LEG  \n",
      "0              24244.50         4835.00  \n",
      "1              16380.66        -2156.74  \n",
      "2              27102.55         8565.15  \n",
      "3              19954.62         1417.22  \n",
      "4              27313.82         8087.92  \n",
      "\n",
      "ABT Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1823296 entries, 0 to 1823295\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Dtype         \n",
      "---  ------                    -----         \n",
      " 0   FL_DATE                   datetime64[ns]\n",
      " 1   OP_CARRIER_FL_NUM         object        \n",
      " 2   ORIGIN                    object        \n",
      " 3   DESTINATION               object        \n",
      " 4   DEP_DELAY                 Float64       \n",
      " 5   ARR_DELAY                 Float64       \n",
      " 6   CANCELLED                 int64         \n",
      " 7   AIR_TIME                  Float64       \n",
      " 8   DISTANCE                  Float64       \n",
      " 9   OCCUPANCY_RATE            Float64       \n",
      " 10  batch_id                  object        \n",
      " 11  ROUTE                     object        \n",
      " 12  CANONICAL_ROUTE_PAIR      object        \n",
      " 13  ORIGIN_AIRPORT_TYPE       object        \n",
      " 14  ORIGIN_AIRPORT_NAME       object        \n",
      " 15  ORIGIN_LATITUDE           float64       \n",
      " 16  ORIGIN_LONGITUDE          float64       \n",
      " 17  DEST_AIRPORT_TYPE         object        \n",
      " 18  DEST_AIRPORT_NAME         object        \n",
      " 19  DEST_LATITUDE             float64       \n",
      " 20  DEST_LONGITUDE            float64       \n",
      " 21  AVG_ROUTE_ITIN_FARE       Float64       \n",
      " 22  COST_FUEL_ETC             Float64       \n",
      " 23  COST_DEPRECIATION_ETC     Float64       \n",
      " 24  COST_AIRPORT_OPERATIONAL  int64         \n",
      " 25  DEP_DELAY_CHARGEABLE      Float64       \n",
      " 26  COST_DEP_DELAY            Float64       \n",
      " 27  ARR_DELAY_CHARGEABLE      Float64       \n",
      " 28  COST_ARR_DELAY            Float64       \n",
      " 29  TOTAL_FLIGHT_COST         Float64       \n",
      " 30  CALCULATED_PASSENGERS     int64         \n",
      " 31  TICKET_REVENUE_PER_LEG    Float64       \n",
      " 32  BAGGAGE_REVENUE_PER_LEG   float64       \n",
      " 33  TOTAL_FLIGHT_REVENUE      Float64       \n",
      " 34  PROFIT_PER_LEG            Float64       \n",
      "dtypes: Float64(16), datetime64[ns](1), float64(5), int64(3), object(10)\n",
      "memory usage: 514.7+ MB\n",
      "\n",
      "Shape of ABT: (1823296, 35)\n",
      "\n",
      "Stats for key engineered features in ABT:\n",
      "\n",
      "--- Stats for ROUTE ---\n",
      "count     1823296\n",
      "unique       5623\n",
      "top       SFO-LAX\n",
      "freq         4175\n",
      "Name: ROUTE, dtype: object\n",
      "Missing values in ROUTE: 0\n",
      "\n",
      "--- Stats for CANONICAL_ROUTE_PAIR ---\n",
      "count     1823296\n",
      "unique       2819\n",
      "top       LAX-SFO\n",
      "freq         8333\n",
      "Name: CANONICAL_ROUTE_PAIR, dtype: object\n",
      "Missing values in CANONICAL_ROUTE_PAIR: 0\n",
      "\n",
      "--- Stats for ORIGIN_AIRPORT_TYPE ---\n",
      "count           1823296\n",
      "unique                2\n",
      "top       large_airport\n",
      "freq            1657429\n",
      "Name: ORIGIN_AIRPORT_TYPE, dtype: object\n",
      "Missing values in ORIGIN_AIRPORT_TYPE: 0\n",
      "\n",
      "--- Stats for DEST_AIRPORT_TYPE ---\n",
      "count           1823296\n",
      "unique                2\n",
      "top       large_airport\n",
      "freq            1657650\n",
      "Name: DEST_AIRPORT_TYPE, dtype: object\n",
      "Missing values in DEST_AIRPORT_TYPE: 0\n",
      "\n",
      "--- Stats for AVG_ROUTE_ITIN_FARE ---\n",
      "count   1804570.00\n",
      "mean        407.72\n",
      "std          95.88\n",
      "min          11.00\n",
      "25%         344.16\n",
      "50%         405.17\n",
      "75%         471.71\n",
      "max         909.00\n",
      "Name: AVG_ROUTE_ITIN_FARE, dtype: Float64\n",
      "Missing values in AVG_ROUTE_ITIN_FARE: 18726\n",
      "\n",
      "--- Stats for COST_FUEL_ETC ---\n",
      "count   1823296.00\n",
      "mean       5387.34\n",
      "std        3314.87\n",
      "min         248.00\n",
      "25%        2744.00\n",
      "50%        4848.00\n",
      "75%        7400.00\n",
      "max       16128.00\n",
      "Name: COST_FUEL_ETC, dtype: Float64\n",
      "Missing values in COST_FUEL_ETC: 0\n",
      "\n",
      "--- Stats for COST_DEPRECIATION_ETC ---\n",
      "count   1823296.00\n",
      "mean        794.63\n",
      "std         488.94\n",
      "min          36.58\n",
      "25%         404.74\n",
      "50%         715.08\n",
      "75%        1091.50\n",
      "max        2378.88\n",
      "Name: COST_DEPRECIATION_ETC, dtype: Float64\n",
      "Missing values in COST_DEPRECIATION_ETC: 0\n",
      "\n",
      "--- Stats for COST_AIRPORT_OPERATIONAL ---\n",
      "count   1823296.00\n",
      "mean       9545.75\n",
      "std        1436.98\n",
      "min        5000.00\n",
      "25%       10000.00\n",
      "50%       10000.00\n",
      "75%       10000.00\n",
      "max       10000.00\n",
      "Name: COST_AIRPORT_OPERATIONAL, dtype: float64\n",
      "Missing values in COST_AIRPORT_OPERATIONAL: 0\n",
      "\n",
      "--- Stats for COST_DEP_DELAY ---\n",
      "count   1823296.00\n",
      "mean         20.09\n",
      "std         102.99\n",
      "min           0.00\n",
      "25%           0.00\n",
      "50%           0.00\n",
      "75%           0.00\n",
      "max         825.00\n",
      "Name: COST_DEP_DELAY, dtype: Float64\n",
      "Missing values in COST_DEP_DELAY: 0\n",
      "\n",
      "--- Stats for COST_ARR_DELAY ---\n",
      "count   1823296.00\n",
      "mean         82.99\n",
      "std         308.42\n",
      "min           0.00\n",
      "25%           0.00\n",
      "50%           0.00\n",
      "75%           0.00\n",
      "max        2025.00\n",
      "Name: COST_ARR_DELAY, dtype: Float64\n",
      "Missing values in COST_ARR_DELAY: 0\n",
      "\n",
      "--- Stats for TOTAL_FLIGHT_COST ---\n",
      "count   1823296.00\n",
      "mean      15830.81\n",
      "std        4283.99\n",
      "min        5284.58\n",
      "25%       12955.96\n",
      "50%       15452.92\n",
      "75%       18436.42\n",
      "max       30893.20\n",
      "Name: TOTAL_FLIGHT_COST, dtype: Float64\n",
      "Missing values in TOTAL_FLIGHT_COST: 0\n",
      "\n",
      "--- Stats for CALCULATED_PASSENGERS ---\n",
      "count   1823296.00\n",
      "mean        130.04\n",
      "std          40.40\n",
      "min          60.00\n",
      "25%          96.00\n",
      "50%         130.00\n",
      "75%         164.00\n",
      "max         200.00\n",
      "Name: CALCULATED_PASSENGERS, dtype: float64\n",
      "Missing values in CALCULATED_PASSENGERS: 0\n",
      "\n",
      "--- Stats for TICKET_REVENUE_PER_LEG ---\n",
      "count   1823296.00\n",
      "mean      26238.19\n",
      "std       10793.70\n",
      "min           0.00\n",
      "25%       18072.48\n",
      "50%       25172.60\n",
      "75%       33359.08\n",
      "max       90900.00\n",
      "Name: TICKET_REVENUE_PER_LEG, dtype: Float64\n",
      "Missing values in TICKET_REVENUE_PER_LEG: 0\n",
      "\n",
      "--- Stats for BAGGAGE_REVENUE_PER_LEG ---\n",
      "count   1823296.00\n",
      "mean       2275.65\n",
      "std         707.00\n",
      "min        1050.00\n",
      "25%        1680.00\n",
      "50%        2275.00\n",
      "75%        2870.00\n",
      "max        3500.00\n",
      "Name: BAGGAGE_REVENUE_PER_LEG, dtype: float64\n",
      "Missing values in BAGGAGE_REVENUE_PER_LEG: 0\n",
      "\n",
      "--- Stats for TOTAL_FLIGHT_REVENUE ---\n",
      "count   1823296.00\n",
      "mean      28513.84\n",
      "std       11337.30\n",
      "min        1050.00\n",
      "25%       19795.41\n",
      "50%       27484.30\n",
      "75%       36157.10\n",
      "max       94400.00\n",
      "Name: TOTAL_FLIGHT_REVENUE, dtype: Float64\n",
      "Missing values in TOTAL_FLIGHT_REVENUE: 0\n",
      "\n",
      "--- Stats for PROFIT_PER_LEG ---\n",
      "count   1823296.00\n",
      "mean      12683.03\n",
      "std       11719.05\n",
      "min      -19789.40\n",
      "25%        3904.44\n",
      "50%       11682.36\n",
      "75%       20139.15\n",
      "max       88628.88\n",
      "Name: PROFIT_PER_LEG, dtype: Float64\n",
      "Missing values in PROFIT_PER_LEG: 0\n",
      "Saved DataFrame to: /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/output_steps/featured_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure all cleaned dataframes are not None and preferably not empty before proceeding\n",
    "abt_df = pd.DataFrame() # Initialize to empty DataFrame\n",
    "\n",
    "# Check if prerequisite dataframes are valid\n",
    "prereq_valid = True\n",
    "if flights_cleaned_df is None or flights_cleaned_df.empty:\n",
    "    print(\"Cleaned flights data is missing or empty. Cannot proceed with feature engineering.\")\n",
    "    prereq_valid = False\n",
    "if tickets_cleaned_df is None: # tickets_cleaned_df can be empty if no 1Q2019 data, but not None\n",
    "    print(\"Cleaned tickets data is None (failed cleaning). Cannot proceed with feature engineering.\")\n",
    "    prereq_valid = False\n",
    "if airport_codes_cleaned_df is None or airport_codes_cleaned_df.empty:\n",
    "    print(\"Cleaned airport codes data is missing or empty. Cannot proceed with feature engineering.\")\n",
    "    prereq_valid = False\n",
    "\n",
    "if prereq_valid:\n",
    "    print(\"\\n--- Starting Feature Engineering ---\")\n",
    "    # The create_analytical_base_table function orchestrates joins and feature calculations.\n",
    "    # It logs DQ metrics internally for joins and new feature creation.\n",
    "    abt_df = feature_engineering_utils.create_analytical_base_table(\n",
    "        flights_cleaned_df,\n",
    "        tickets_cleaned_df, # This can be an empty DataFrame if no valid tickets were found\n",
    "        airport_codes_cleaned_df\n",
    "    )\n",
    "\n",
    "    if abt_df is not None and not abt_df.empty:\n",
    "        print(\"\\n--- Analytical Base Table (ABT) Created ---\")\n",
    "        print(\"ABT Head:\")\n",
    "        print(abt_df.head())\n",
    "        print(\"\\nABT Info:\")\n",
    "        abt_df.info()\n",
    "        print(f\"\\nShape of ABT: {abt_df.shape}\")\n",
    "\n",
    "        # Display some stats for key engineered features\n",
    "        print(\"\\nStats for key engineered features in ABT:\")\n",
    "        key_features_to_check = [\n",
    "            'ROUTE', 'CANONICAL_ROUTE_PAIR', 'ORIGIN_AIRPORT_TYPE', 'DEST_AIRPORT_TYPE',\n",
    "            'AVG_ROUTE_ITIN_FARE', 'COST_FUEL_ETC', 'COST_DEPRECIATION_ETC',\n",
    "            'COST_AIRPORT_OPERATIONAL', 'COST_DEP_DELAY', 'COST_ARR_DELAY',\n",
    "            'TOTAL_FLIGHT_COST', 'CALCULATED_PASSENGERS',\n",
    "            'TICKET_REVENUE_PER_LEG', 'BAGGAGE_REVENUE_PER_LEG',\n",
    "            'TOTAL_FLIGHT_REVENUE', 'PROFIT_PER_LEG'\n",
    "        ]\n",
    "        for col in key_features_to_check:\n",
    "            if col in abt_df.columns:\n",
    "                print(f\"\\n--- Stats for {col} ---\")\n",
    "                print(abt_df[col].describe(include='all'))\n",
    "                print(f\"Missing values in {col}: {abt_df[col].isnull().sum()}\")\n",
    "            else:\n",
    "                print(f\"Column {col} was expected but not found in ABT.\")\n",
    "    elif abt_df is not None and abt_df.empty:\n",
    "         print(\"Analytical Base Table (ABT) was created but is empty. This likely means joins resulted in no matching records.\")\n",
    "         print(\"Review join conditions, filters in cleaning, and DQ logs from feature_engineering_utils.\")\n",
    "    else: # abt_df is None\n",
    "        print(\"Analytical Base Table (ABT) creation failed or returned None.\")\n",
    "else:\n",
    "    print(\"One or more cleaned dataframes are not suitable for feature engineering. Skipping ABT creation.\")\n",
    "    # Ensure abt_df is an empty DataFrame if it couldn't be created\n",
    "    if 'abt_df' not in locals() or abt_df is None:\n",
    "         abt_df = pd.DataFrame()\n",
    "\n",
    "step_name = \"featured_data\"\n",
    "file_name = f\"{step_name}.csv\"\n",
    "output_file_path = os.path.join(config.STEP_OUTPUT_DIR, file_name)\n",
    "batch_timestamp = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M\")\n",
    "\n",
    "abt_df.loc[:, 'batch_id'] = batch_timestamp\n",
    "\n",
    "abt_df.to_csv(output_file_path, index=False)\n",
    "print(f\"Saved DataFrame to: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Metadata for Newly Engineered Fields (examples from `config.py` and `feature_engineering_utils.py`):**\n",
    "\n",
    " ### Metadata for Newly Engineered Columns in ABT\n",
    "\n",
    "| New Column Name          | Data Type (in ABT) | Description                                                                                                | Source/Phase Added                                  |\n",
    "| :----------------------- | :----------------- | :--------------------------------------------------------------------------------------------------------- | :-------------------------------------------------- |\n",
    "| `ROUTE`                  | object (string)    | Concatenation of Origin and Destination airport codes (e.g., \"JFK-ORD\").                                   | `feature_engineering_utils.py` (create_route_columns) |\n",
    "| `CANONICAL_ROUTE_PAIR`   | object (string)    | Standardized round-trip identifier (e.g., \"JFK-ORD\" for both JFK-ORD and ORD-JFK).                         | `feature_engineering_utils.py` (create_route_columns) |\n",
    "| `ORIGIN_AIRPORT_TYPE`    | object (string)    | Type of the origin airport (e.g., 'large_airport', 'medium_airport').                                      | `feature_engineering_utils.py` (join_flights_with_airports) |\n",
    "| `ORIGIN_AIRPORT_NAME`    | object (string)    | Full name of the origin airport.                                                                           | `feature_engineering_utils.py` (join_flights_with_airports) |\n",
    "| `ORIGIN_LATITUDE`        | Float64            | Latitude of the origin airport.                                                                            | `feature_engineering_utils.py` (join_flights_with_airports) / `clean_utils.py` (airport cleaning) |\n",
    "| `ORIGIN_LONGITUDE`       | Float64            | Longitude of the origin airport.                                                                           | `feature_engineering_utils.py` (join_flights_with_airports) / `clean_utils.py` (airport cleaning) |\n",
    "| `DEST_AIRPORT_TYPE`      | object (string)    | Type of the destination airport.                                                                           | `feature_engineering_utils.py` (join_flights_with_airports) |\n",
    "| `DEST_AIRPORT_NAME`      | object (string)    | Full name of the destination airport.                                                                      | `feature_engineering_utils.py` (join_flights_with_airports) |\n",
    "| `DEST_LATITUDE`          | Float64            | Latitude of the destination airport.                                                                       | `feature_engineering_utils.py` (join_flights_with_airports) / `clean_utils.py` (airport cleaning) |\n",
    "| `DEST_LONGITUDE`         | Float64            | Longitude of the destination airport.                                                                      | `feature_engineering_utils.py` (join_flights_with_airports) / `clean_utils.py` (airport cleaning) |\n",
    "| `AVG_ROUTE_ITIN_FARE`    | Float64            | Average round-trip itinerary fare per person for the route, derived from sample Tickets data.                | `feature_engineering_utils.py` (join_with_tickets_data) |\n",
    "| `COST_FUEL_ETC`          | Float64 or Int64   | Cost for fuel, oil, maintenance, and crew per flight leg.                                                  | `feature_engineering_utils.py` (calculate_flight_costs) |\n",
    "| `COST_DEPRECIATION_ETC`  | Float64            | Cost for depreciation, insurance, and other items per flight leg.                                          | `feature_engineering_utils.py` (calculate_flight_costs) |\n",
    "| `COST_AIRPORT_OPERATIONAL`| int64 or float64   | Landing fee at the destination airport for a flight leg.                                                   | `feature_engineering_utils.py` (calculate_flight_costs) |\n",
    "| `DEP_DELAY_CHARGEABLE`   | Float64            | Departure delay minutes exceeding the free allowance, used for cost calculation.                           | `feature_engineering_utils.py` (calculate_flight_costs) |\n",
    "| `COST_DEP_DELAY`         | Float64            | Cost incurred due to departure delays.                                                                     | `feature_engineering_utils.py` (calculate_flight_costs) |\n",
    "| `ARR_DELAY_CHARGEABLE`   | Float64            | Arrival delay minutes exceeding the free allowance, used for cost calculation.                             | `feature_engineering_utils.py` (calculate_flight_costs) |\n",
    "| `COST_ARR_DELAY`         | Float64            | Cost incurred due to arrival delays.                                                                       | `feature_engineering_utils.py` (calculate_flight_costs) |\n",
    "| `TOTAL_FLIGHT_COST`      | Float64            | Sum of all operational cost components for a single flight leg.                                            | `feature_engineering_utils.py` (calculate_flight_costs) |\n",
    "| `CALCULATED_PASSENGERS`  | int64              | Estimated number of passengers on a flight based on occupancy rate.                                        | `feature_engineering_utils.py` (calculate_flight_revenue) |\n",
    "| `TICKET_REVENUE_PER_LEG` | Float64            | Estimated ticket revenue for a single flight leg (AVG_ROUTE_ITIN_FARE/2 * passengers).                       | `feature_engineering_utils.py` (calculate_flight_revenue) |\n",
    "| `BAGGAGE_REVENUE_PER_LEG`| float64            | Estimated baggage revenue for a single flight leg.                                                         | `feature_engineering_utils.py` (calculate_flight_revenue) |\n",
    "| `TOTAL_FLIGHT_REVENUE`   | Float64            | Sum of ticket and baggage revenue for a single flight leg.                                                 | `feature_engineering_utils.py` (calculate_flight_revenue) |\n",
    "| `PROFIT_PER_LEG`         | Float64            | Operational profit for a single flight leg (TOTAL_FLIGHT_REVENUE - TOTAL_FLIGHT_COST).                     | `feature_engineering_utils.py` (calculate_flight_revenue) |\n",
    "| `AVG_TOTAL_DELAY`        | Float64            | Sum of average departure and arrival delay for a route (created in analysis_utils for scoring).            | `analysis_utils.py` (recommend_routes_advanced_scoring) |\n",
    "| `PROFIT_PER_FLIGHT`      | Float64            | Total profit for a canonical route pair divided by the number of round trip flights on that pair.          | `analysis_utils.py` (identify_most_profitable_round_trip_routes) |\n",
    "| `BREAKEVEN_ROUND_TRIP_FLIGHTS` | Float64 or Int64 | Number of round trip flights needed to cover the $90M airplane cost for a route.                       | `analysis_utils.py` (calculate_breakeven_flights) |\n",
    "| `COMPOSITE_SCORE`        | float64            | Overall score assigned to a route by the advanced recommendation model.                                    | `analysis_utils.py` (recommend_routes_advanced_scoring) |\n",
    "| `RANK`                   | int64              | Rank of the route based on the composite score.                                                            | `analysis_utils.py` (recommend_routes_advanced_scoring) |\n",
    "| `IS_RECOMMENDED`         | boolean            | Flag indicating if a route is part of the final recommendations (used for Tableau export).                 | Notebook (Tableau Export Cell)                      |\n",
    "| `BATCH_ID`               | object (string)    | Timestamp indicating when the data (e.g., intermediate CSV) was generated/processed for that specific run. | Notebook (CSV Saving Cells) / `clean_utils.py` (for rejected data) |\n",
    "| `FILTER_REASON`          | object (string)    | Column added to rejected data CSVs explaining why a row was filtered out.                                  | `clean_utils.py` (_save_rejected_data)              |\n",
    "| `REJECT_RUN_ID`          | object (string)    | Run ID associated with the cleaning run that produced the rejected row.                                    | `clean_utils.py` (_save_rejected_data)              |\n",
    "| `REJECT_TIMESTAMP`       | object (string)    | Timestamp of when the row was rejected during the cleaning process.                                        | `clean_utils.py` (_save_rejected_data)              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQ log for Run ID 49ec5f94-94e7-4896-94ba-67fc53ec3155 saved to /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/logs/dq_metrics.csv\n",
      "Full DQ log for Phase 1 saved to /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/logs/dq_metrics.csv\n",
      "\n",
      "--- Data Quality Log Summary ---\n",
      "Run ID: 49ec5f94-94e7-4896-94ba-67fc53ec3155\n",
      "Total DQ metrics logged: 66\n",
      "Last 5 entries:\n",
      "              Timestamp                                 RunID  \\\n",
      "61  2025-05-13 21:40:52  49ec5f94-94e7-4896-94ba-67fc53ec3155   \n",
      "62  2025-05-13 21:40:52  49ec5f94-94e7-4896-94ba-67fc53ec3155   \n",
      "63  2025-05-13 21:40:52  49ec5f94-94e7-4896-94ba-67fc53ec3155   \n",
      "64  2025-05-13 21:40:52  49ec5f94-94e7-4896-94ba-67fc53ec3155   \n",
      "65  2025-05-13 21:40:52  49ec5f94-94e7-4896-94ba-67fc53ec3155   \n",
      "\n",
      "                                        Phase  \\\n",
      "61  Data Transformation & Feature Engineering   \n",
      "62  Data Transformation & Feature Engineering   \n",
      "63  Data Transformation & Feature Engineering   \n",
      "64  Data Transformation & Feature Engineering   \n",
      "65  Data Transformation & Feature Engineering   \n",
      "\n",
      "                                      Step                     TableName  \\\n",
      "61              Join Flights with Airports  Flights_Merged_With_Airports   \n",
      "62              Join Flights with Airports  Flights_Merged_With_Airports   \n",
      "63              Join Flights with Airports  Flights_Merged_With_Airports   \n",
      "64  Join Flights with Tickets (Aggregated)         Flights_With_Airports   \n",
      "65  Join Flights with Tickets (Aggregated)               Tickets_Cleaned   \n",
      "\n",
      "                                 Metric    Value Description  \n",
      "61       Rows After Origin Airport Join  1838774              \n",
      "62  Rows After Destination Airport Join  1823296              \n",
      "63  Final Row Count After Airport Joins  1823296              \n",
      "64         Row Count Before Ticket Join  1823296              \n",
      "65                            Row Count   699191              \n",
      "--- End of DQ Log Summary ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save the complete DQ log at the end of Phase 1 (Data Foundation)\n",
    "# This includes logs from loading, cleaning, and feature engineering.\n",
    "dq_utils.save_dq_log_to_csv(config.DQ_LOG_FILE_PATH)\n",
    "print(f\"Full DQ log for Phase 1 saved to {config.DQ_LOG_FILE_PATH}\")\n",
    "\n",
    "# Display a summary of the DQ log from the current run\n",
    "dq_utils.display_dq_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Analytical Insights & Visualization\n",
    " \n",
    "\n",
    "1. Identify Busiest Routes: Determine and list the top 10 busiest round-trip routes based on flight volume.\n",
    "2. Identify Most Profitable Routes: Determine and list the top 10 most profitable round-trip routes (pre-airplane cost), along with their key financial and operational metrics.\n",
    "3. Calculate Breakeven for Profitable Routes: For all routes identified as profitable, calculate their breakeven flight volume considering the airplane investment cost.\n",
    "4. Recommend Top Routes (Advanced Scoring): Apply a multi-factored scoring model (using profitability, demand, operational efficiency, and investment viability metrics) to select and rank the top 5 routes for investment.\n",
    "5. Display Breakeven for Recommended Routes: Specifically show the breakeven analysis details for the 5 finally recommended routes.\n",
    "6. Prepare Data for Visualization: Export the key analytical datasets (e.g., route metrics, recommendations, DQ logs) for use in Tableau or other BI tools.\n",
    "\n",
    "\n",
    "\n",
    " ### Task 2.1: Answer Core Business Questions (Calculations in Python)\n",
    " 1.  Determine the 10 busiest round trip routes by number of round trip flights.\n",
    " 2.  Determine the 10 most profitable round trip routes (pre-airplane cost) and their associated metrics.\n",
    "\n",
    " #### Q1: The 10 Busiest Round Trip Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Q1: Identifying 10 Busiest Round Trip Routes ---\n",
      "\n",
      "--- Top 10 Busiest Round Trip Routes ---\n",
      "     CANONICAL_ROUTE_PAIR  ROUND_TRIP_FLIGHTS\n",
      "2156              LAX-SFO                4166\n",
      "2197              LGA-ORD                3573\n",
      "2060              LAS-LAX                3253\n",
      "2004              JFK-LAX                3149\n",
      "2155              LAX-SEA                2496\n",
      "546               BOS-LGA                2408\n",
      "1766              HNL-OGG                2396\n",
      "2611              PDX-SEA                2385\n",
      "190               ATL-MCO                2353\n",
      "186               ATL-LGA                2294\n",
      "Saved DataFrame to: /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/output_steps/04_busiest_routes.csv\n"
     ]
    }
   ],
   "source": [
    "busiest_routes_df = pd.DataFrame() \n",
    "if 'abt_df' in locals() and abt_df is not None and not abt_df.empty:\n",
    "    print(\"\\n--- Q1: Identifying 10 Busiest Round Trip Routes ---\")\n",
    "    if 'CANONICAL_ROUTE_PAIR' not in abt_df.columns:\n",
    "        print(\"Error: 'CANONICAL_ROUTE_PAIR' column not found in ABT. Cannot determine busiest routes.\")\n",
    "    else:\n",
    "        busiest_routes_df = analysis_utils.identify_busiest_round_trip_routes(abt_df.copy(), top_n=10)\n",
    "        if not busiest_routes_df.empty:\n",
    "            # plt.figure(figsize=(12, 7))\n",
    "            # sns.barplot(x='ROUND_TRIP_FLIGHTS', y='CANONICAL_ROUTE_PAIR', data=busiest_routes_df, palette='viridis', hue='CANONICAL_ROUTE_PAIR', dodge=False, legend=False)\n",
    "            # plt.title('Top 10 Busiest Round Trip Routes (1Q2019)')\n",
    "            # plt.xlabel('Number of Round Trip Flights'); plt.ylabel('Round Trip Route')\n",
    "            # plt.tight_layout(); plt.show()\n",
    "            # Save intermediate output\n",
    "            step_name = \"04_busiest_routes\"\n",
    "            file_name = f\"{step_name}.csv\"; output_file_path = os.path.join(config.STEP_OUTPUT_DIR, file_name)\n",
    "            df_to_save = busiest_routes_df.copy()\n",
    "            df_to_save.loc[:, config.BATCH_ID_COLUMN] = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]\n",
    "            df_to_save.to_csv(output_file_path, index=False); print(f\"Saved DataFrame to: {output_file_path}\")\n",
    "        else:\n",
    "            print(\"Could not determine busiest routes.\")\n",
    "else:\n",
    "    print(\"ABT is empty or not available. Skipping Q1 analysis (Busiest Routes).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: The 10 Most Profitable Round Trip Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Q2: Identifying 10 Most Profitable Round Trip Routes ---\n",
      "\n",
      "--- Top 10 Most Profitable Round Trip Routes (excluding upfront airplane cost) ---\n",
      "     CANONICAL_ROUTE_PAIR  TOTAL_PROFIT  PROFIT_PER_FLIGHT  TOTAL_REVENUE  \\\n",
      "1985              JFK-LAX   99252298.23           31518.67   202069077.44   \n",
      "1111              DCA-ORD   73399227.77           39804.35   131355101.85   \n",
      "1095              DCA-LGA   69124622.46           41194.65   109716451.58   \n",
      "540               BOS-LGA   66398343.46           27574.06   123197970.38   \n",
      "129               ATL-CLT   65900851.44           42876.29   103257592.76   \n",
      "2135              LAX-SFO   63654207.51           15279.45   173868501.29   \n",
      "833               CLT-GSP   61872487.00           80042.03    78516796.50   \n",
      "2011              JFK-SFO   57715834.19           31197.75   118210322.42   \n",
      "1286              DFW-IAH   57277348.38           38779.52    93256592.66   \n",
      "2176              LGA-ORD   56426861.22           15792.57   177049691.46   \n",
      "\n",
      "       TOTAL_COST  ROUND_TRIP_FLIGHTS  TOTAL_DISTANCE_MILES  AVG_DEP_DELAY  \\\n",
      "1985 102816779.21                3149            4271893.16          -1.51   \n",
      "1111  57955874.08                1844            2257056.00          -2.85   \n",
      "1095  40591829.12                1678             718184.00          -2.72   \n",
      "540   56799626.92                2408             886144.00          -2.49   \n",
      "129   37356741.32                1537             694724.00          -1.36   \n",
      "2135 110214293.78                4166            2808221.00          -1.61   \n",
      "833   16644309.50                 773             116025.00          -1.28   \n",
      "2011  60494488.23                1850            2509287.93          -1.51   \n",
      "1286  35979244.28                1477             661696.00          -1.00   \n",
      "2176 120622830.24                3573            5238018.00          -1.26   \n",
      "\n",
      "      AVG_ARR_DELAY  AVG_OCCUPANCY  \n",
      "1985         -10.27           0.65  \n",
      "1111          -6.76           0.65  \n",
      "1095          -5.26           0.65  \n",
      "540           -8.00           0.65  \n",
      "129           -6.23           0.65  \n",
      "2135          -4.98           0.65  \n",
      "833           -6.71           0.65  \n",
      "2011          -8.58           0.65  \n",
      "1286          -0.07           0.65  \n",
      "2176          -4.26           0.65  \n",
      "Saved DataFrame to: /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/output_steps/05_most_profitable_routes.csv\n"
     ]
    }
   ],
   "source": [
    "most_profitable_routes_df = pd.DataFrame()\n",
    "if 'abt_df' in locals() and abt_df is not None and not abt_df.empty:\n",
    "    print(\"\\n--- Q2: Identifying 10 Most Profitable Round Trip Routes ---\")\n",
    "    # ... (checks for required columns and AVG_ROUTE_ITIN_FARE as in your notebook) ...\n",
    "    most_profitable_routes_df = analysis_utils.identify_most_profitable_round_trip_routes(abt_df.copy(), top_n=10) # top_n can be larger if we want to score more routes\n",
    "    if not most_profitable_routes_df.empty:\n",
    "        # Save intermediate output\n",
    "        step_name = \"05_most_profitable_routes\"\n",
    "        file_name = f\"{step_name}.csv\"; output_file_path = os.path.join(config.STEP_OUTPUT_DIR, file_name)\n",
    "        df_to_save = most_profitable_routes_df.copy()\n",
    "        df_to_save.loc[:, config.BATCH_ID_COLUMN] = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]\n",
    "        df_to_save.to_csv(output_file_path, index=False); print(f\"Saved DataFrame to: {output_file_path}\")\n",
    "    else:\n",
    "        print(\"Could not determine most profitable routes.\")\n",
    "else:\n",
    "    print(\"ABT is empty or not available. Skipping Q2 analysis (Most Profitable Routes).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Calculate Breakeven for Profitable Routes (Input for Q3 Recommendation)\n",
    " This step calculates the breakeven point for all routes identified as potentially profitable. This information will then be used in the advanced scoring model for recommendations. This addresses part of Q4 from the problem statement upfront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Calculating Breakeven Analysis for All Profitable Routes ---\n",
      "\n",
      "--- Calculating Breakeven Flights (Airplane Cost: $90,000,000) ---\n",
      "  CANONICAL_ROUTE_PAIR  PROFIT_PER_FLIGHT  BREAKEVEN_ROUND_TRIP_FLIGHTS  \\\n",
      "0              JFK-LAX           31518.67                       2856.00   \n",
      "1              DCA-ORD           39804.35                       2262.00   \n",
      "2              DCA-LGA           41194.65                       2185.00   \n",
      "3              BOS-LGA           27574.06                       3264.00   \n",
      "4              ATL-CLT           42876.29                       2100.00   \n",
      "5              LAX-SFO           15279.45                       5891.00   \n",
      "6              CLT-GSP           80042.03                       1125.00   \n",
      "7              JFK-SFO           31197.75                       2885.00   \n",
      "8              DFW-IAH           38779.52                       2321.00   \n",
      "9              LGA-ORD           15792.57                       5699.00   \n",
      "\n",
      "   TOTAL_PROFIT  ROUND_TRIP_FLIGHTS  AVG_DEP_DELAY  AVG_ARR_DELAY  \n",
      "0   99252298.23                3149          -1.51         -10.27  \n",
      "1   73399227.77                1844          -2.85          -6.76  \n",
      "2   69124622.46                1678          -2.72          -5.26  \n",
      "3   66398343.46                2408          -2.49          -8.00  \n",
      "4   65900851.44                1537          -1.36          -6.23  \n",
      "5   63654207.51                4166          -1.61          -4.98  \n",
      "6   61872487.00                 773          -1.28          -6.71  \n",
      "7   57715834.19                1850          -1.51          -8.58  \n",
      "8   57277348.38                1477          -1.00          -0.07  \n",
      "9   56426861.22                3573          -1.26          -4.26  \n",
      "\n",
      "Breakeven Analysis Calculated for 10 profitable routes.\n",
      "  CANONICAL_ROUTE_PAIR  PROFIT_PER_FLIGHT  BREAKEVEN_ROUND_TRIP_FLIGHTS  \\\n",
      "0              JFK-LAX           31518.67                       2856.00   \n",
      "1              DCA-ORD           39804.35                       2262.00   \n",
      "2              DCA-LGA           41194.65                       2185.00   \n",
      "3              BOS-LGA           27574.06                       3264.00   \n",
      "4              ATL-CLT           42876.29                       2100.00   \n",
      "\n",
      "   TOTAL_PROFIT  ROUND_TRIP_FLIGHTS  AVG_DEP_DELAY  AVG_ARR_DELAY  \n",
      "0   99252298.23                3149          -1.51         -10.27  \n",
      "1   73399227.77                1844          -2.85          -6.76  \n",
      "2   69124622.46                1678          -2.72          -5.26  \n",
      "3   66398343.46                2408          -2.49          -8.00  \n",
      "4   65900851.44                1537          -1.36          -6.23  \n",
      "Saved DataFrame to: /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/output_steps/06_breakeven_for_all_profitable_routes.csv\n"
     ]
    }
   ],
   "source": [
    "breakeven_for_all_profitable_df = pd.DataFrame()\n",
    "if 'most_profitable_routes_df' in locals() and not most_profitable_routes_df.empty:\n",
    "    print(\"\\n--- Calculating Breakeven Analysis for All Profitable Routes ---\")\n",
    "    # We use most_profitable_routes_df for both arguments as it contains the list of routes\n",
    "    # and the necessary 'PROFIT_PER_FLIGHT' detail.\n",
    "    breakeven_for_all_profitable_df = analysis_utils.calculate_breakeven_flights(\n",
    "        most_profitable_routes_df, # Provides CANONICAL_ROUTE_PAIR for routes to analyze\n",
    "        most_profitable_routes_df  # Provides the detailed profit metrics including PROFIT_PER_FLIGHT\n",
    "    )\n",
    "    if not breakeven_for_all_profitable_df.empty:\n",
    "        print(f\"\\nBreakeven Analysis Calculated for {len(breakeven_for_all_profitable_df)} profitable routes.\")\n",
    "        print(breakeven_for_all_profitable_df.head())\n",
    "        # Save intermediate output\n",
    "        step_name = \"06_breakeven_for_all_profitable_routes\"\n",
    "        file_name = f\"{step_name}.csv\"; output_file_path = os.path.join(config.STEP_OUTPUT_DIR, file_name)\n",
    "        df_to_save = breakeven_for_all_profitable_df.copy()\n",
    "        df_to_save.loc[:, config.BATCH_ID_COLUMN] = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]\n",
    "        df_to_save.to_csv(output_file_path, index=False); print(f\"Saved DataFrame to: {output_file_path}\")\n",
    "    else:\n",
    "        print(\"Could not perform breakeven analysis for profitable routes.\")\n",
    "else:\n",
    "    print(\"Most profitable routes data is not available. Skipping breakeven calculation for all profitable routes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Route Recommendation (Q3 - Using Advanced Scoring)\n",
    " - Define recommendation criteria (as per your detailed approach).\n",
    " - Prepare a comprehensive DataFrame for scoring.\n",
    " - Implement advanced scoring logic to select 5 routes.\n",
    " - Justify the selection of 5 routes in detail.\n",
    "\n",
    " **Route Recommendation Criteria & Scoring Model:**\n",
    " (This markdown section should summarize your detailed approach: Key Considerations, Model Design, Metrics & Importance, Weight Distribution, as you outlined)\n",
    "\n",
    " Example Summary:\n",
    " The recommendation model uses a multi-factored approach:\n",
    " 1. **Metrics:** Total Profit, Profit Per Flight, Flight Volume (Round Trip Flights), Average Occupancy, Average Total Delay (Departure + Arrival), and Breakeven Round Trip Flights.\n",
    " 2. **Normalization:** Min-Max scaling (0-100) for each metric.\n",
    " 3. **Weights:**\n",
    "     - Profitability (Total Profit 25%, Profit Per Flight 15%) = 40%\n",
    "     - Market Demand (Flight Volume) = 20%\n",
    "     - Operational Factors (Punctuality/Avg Total Delay 15%, Occupancy 10%) = 25%\n",
    "     - Investment Efficiency (Breakeven Flights Score) = 15%\n",
    " 4. **Scoring:** Weighted sum of normalized scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Q3: Recommending 5 Round Trip Routes for Investment (Advanced Scoring) ---\n",
      "Shape of data input to scoring: (10, 12)\n",
      "\n",
      "--- Recommend 5 Routes (Advanced Scoring) ---\n",
      "Composite Score calculated using: (NORM_TOTAL_PROFIT * 0.25) + (NORM_PROFIT_PER_FLIGHT * 0.15) + (NORM_ROUND_TRIP_FLIGHTS * 0.2) + (NORM_AVG_TOTAL_DELAY * 0.15) + (NORM_AVG_OCCUPANCY * 0.1) + (NORM_BREAKEVEN_ROUND_TRIP_FLIGHTS * 0.15)\n",
      "\n",
      "--- Top 5 Recommended Routes (Advanced Scoring) ---\n",
      "   RANK CANONICAL_ROUTE_PAIR  COMPOSITE_SCORE  TOTAL_PROFIT  \\\n",
      "0     1              JFK-LAX            72.02   99252298.23   \n",
      "2     2              DCA-LGA            50.09   69124622.46   \n",
      "6     3              CLT-GSP            46.59   61872487.00   \n",
      "3     4              BOS-LGA            46.14   66398343.46   \n",
      "1     5              DCA-ORD            45.28   73399227.77   \n",
      "\n",
      "   PROFIT_PER_FLIGHT  ROUND_TRIP_FLIGHTS  AVG_OCCUPANCY  AVG_TOTAL_DELAY  \\\n",
      "0           31518.67                3149           0.65           -11.78   \n",
      "2           41194.65                1678           0.65            -7.98   \n",
      "6           80042.03                 773           0.65            -7.99   \n",
      "3           27574.06                2408           0.65           -10.49   \n",
      "1           39804.35                1844           0.65            -9.61   \n",
      "\n",
      "   BREAKEVEN_ROUND_TRIP_FLIGHTS  NORM_TOTAL_PROFIT  NORM_PROFIT_PER_FLIGHT  \\\n",
      "0                       2856.00             100.00                   25.08   \n",
      "2                       2185.00              29.65                   40.02   \n",
      "6                       1125.00              12.72                  100.00   \n",
      "3                       3264.00              23.28                   18.98   \n",
      "1                       2262.00              39.63                   37.87   \n",
      "\n",
      "   NORM_ROUND_TRIP_FLIGHTS  NORM_AVG_OCCUPANCY  NORM_AVG_TOTAL_DELAY  \\\n",
      "0                    70.03               47.04                100.00   \n",
      "2                    26.67              100.00                 64.50   \n",
      "6                     0.00               37.23                 64.59   \n",
      "3                    48.19               63.77                 87.95   \n",
      "1                    31.56                0.00                 79.70   \n",
      "\n",
      "   NORM_BREAKEVEN_ROUND_TRIP_FLIGHTS  \n",
      "0                              63.68  \n",
      "2                              77.76  \n",
      "6                             100.00  \n",
      "3                              55.12  \n",
      "1                              76.14  \n",
      "\n",
      "--- Top 5 Recommended Routes (Advanced Scoring) ---\n",
      "   RANK CANONICAL_ROUTE_PAIR  COMPOSITE_SCORE  TOTAL_PROFIT  \\\n",
      "0     1              JFK-LAX            72.02   99252298.23   \n",
      "2     2              DCA-LGA            50.09   69124622.46   \n",
      "6     3              CLT-GSP            46.59   61872487.00   \n",
      "3     4              BOS-LGA            46.14   66398343.46   \n",
      "1     5              DCA-ORD            45.28   73399227.77   \n",
      "\n",
      "   PROFIT_PER_FLIGHT  ROUND_TRIP_FLIGHTS  AVG_TOTAL_DELAY  AVG_OCCUPANCY  \\\n",
      "0           31518.67                3149           -11.78           0.65   \n",
      "2           41194.65                1678            -7.98           0.65   \n",
      "6           80042.03                 773            -7.99           0.65   \n",
      "3           27574.06                2408           -10.49           0.65   \n",
      "1           39804.35                1844            -9.61           0.65   \n",
      "\n",
      "   BREAKEVEN_ROUND_TRIP_FLIGHTS  NORM_TOTAL_PROFIT  NORM_PROFIT_PER_FLIGHT  \\\n",
      "0                       2856.00             100.00                   25.08   \n",
      "2                       2185.00              29.65                   40.02   \n",
      "6                       1125.00              12.72                  100.00   \n",
      "3                       3264.00              23.28                   18.98   \n",
      "1                       2262.00              39.63                   37.87   \n",
      "\n",
      "   NORM_ROUND_TRIP_FLIGHTS  NORM_AVG_OCCUPANCY  NORM_AVG_TOTAL_DELAY  \\\n",
      "0                    70.03               47.04                100.00   \n",
      "2                    26.67              100.00                 64.50   \n",
      "6                     0.00               37.23                 64.59   \n",
      "3                    48.19               63.77                 87.95   \n",
      "1                    31.56                0.00                 79.70   \n",
      "\n",
      "   NORM_BREAKEVEN_ROUND_TRIP_FLIGHTS  \n",
      "0                              63.68  \n",
      "2                              77.76  \n",
      "6                             100.00  \n",
      "3                              55.12  \n",
      "1                              76.14  \n",
      "Saved DataFrame to: /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/output_steps/07_advanced_recommendations.csv\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for advanced recommendation\n",
    "all_metrics_for_scoring_df = pd.DataFrame()\n",
    "advanced_recommendations_df = pd.DataFrame()\n",
    "\n",
    "if 'most_profitable_routes_df' in locals() and not most_profitable_routes_df.empty:\n",
    "    all_metrics_for_scoring_df = most_profitable_routes_df.copy()\n",
    "\n",
    "    # Merge breakeven analysis data (BREAKEVEN_ROUND_TRIP_FLIGHTS)\n",
    "    if 'breakeven_for_all_profitable_df' in locals() and not breakeven_for_all_profitable_df.empty:\n",
    "        all_metrics_for_scoring_df = pd.merge(\n",
    "            all_metrics_for_scoring_df,\n",
    "            breakeven_for_all_profitable_df[['CANONICAL_ROUTE_PAIR', 'BREAKEVEN_ROUND_TRIP_FLIGHTS']],\n",
    "            on='CANONICAL_ROUTE_PAIR',\n",
    "            how='left' \n",
    "            # Left join is appropriate: we want to score all profitable routes, \n",
    "            # and add breakeven info if available (it should be for those with positive profit per flight)\n",
    "        )\n",
    "    else:\n",
    "        print(\"Warning: Breakeven data for all profitable routes not available. 'BREAKEVEN_ROUND_TRIP_FLIGHTS' will be missing for scoring.\")\n",
    "        all_metrics_for_scoring_df['BREAKEVEN_ROUND_TRIP_FLIGHTS'] = np.nan # Ensure column exists if expected by scorer\n",
    "\n",
    "    # The 'ROUND_TRIP_FLIGHTS' for volume is already in most_profitable_routes_df.\n",
    "    # If busiest_routes_df had a more definitive or different volume metric, it could be merged here.\n",
    "    # For now, we assume most_profitable_routes_df.ROUND_TRIP_FLIGHTS is the primary volume indicator for these routes.\n",
    "    \n",
    "    print(f\"\\n--- Q3: Recommending 5 Round Trip Routes for Investment (Advanced Scoring) ---\")\n",
    "    print(f\"Shape of data input to scoring: {all_metrics_for_scoring_df.shape}\")\n",
    "    if not all_metrics_for_scoring_df.empty:\n",
    "        advanced_recommendations_df = analysis_utils.recommend_routes_advanced_scoring(\n",
    "            all_metrics_for_scoring_df,\n",
    "            num_recommendations=5\n",
    "        )\n",
    "\n",
    "        if not advanced_recommendations_df.empty:\n",
    "            print(\"\\n--- Top 5 Recommended Routes (Advanced Scoring) ---\")\n",
    "            # Display relevant columns for the recommendation justification\n",
    "            cols_to_display_rec = ['RANK', 'CANONICAL_ROUTE_PAIR', 'COMPOSITE_SCORE',\n",
    "                                   'TOTAL_PROFIT', 'PROFIT_PER_FLIGHT', 'ROUND_TRIP_FLIGHTS',\n",
    "                                   'AVG_TOTAL_DELAY', 'AVG_OCCUPANCY', 'BREAKEVEN_ROUND_TRIP_FLIGHTS']\n",
    "            # Add normalized scores if you want to see them\n",
    "            norm_cols_to_add = [col for col in advanced_recommendations_df.columns if col.startswith('NORM_')]\n",
    "            cols_to_display_rec.extend(norm_cols_to_add)\n",
    "            \n",
    "            cols_to_display_rec = [col for col in cols_to_display_rec if col in advanced_recommendations_df.columns]\n",
    "            print(advanced_recommendations_df[cols_to_display_rec])\n",
    "            \n",
    "            # Save intermediate output\n",
    "            step_name = \"07_advanced_recommendations\"\n",
    "            file_name = f\"{step_name}.csv\"; output_file_path = os.path.join(config.STEP_OUTPUT_DIR, file_name)\n",
    "            df_to_save = advanced_recommendations_df.copy()\n",
    "            df_to_save.loc[:, config.BATCH_ID_COLUMN] = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]\n",
    "            df_to_save.to_csv(output_file_path, index=False); print(f\"Saved DataFrame to: {output_file_path}\")\n",
    "        else:\n",
    "            print(\"Could not make route recommendations using advanced scoring.\")\n",
    "    else:\n",
    "        print(\"Data for scoring (all_metrics_for_scoring_df) is empty. Skipping advanced recommendation.\")\n",
    "else:\n",
    "    print(\"Most profitable routes data is not available. Cannot proceed with advanced recommendations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Task 2.3: Breakeven Analysis for Recommended Routes (Q4 - Display)\n",
    " - Display breakeven points and key summary components for the 5 routes *that were just recommended* by the advanced scoring model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Q4: Breakeven Analysis for the 5 Recommended Routes ---\n",
      "\n",
      "Breakeven Analysis (Airplane Upfront Cost: $90,000,000 per route) for Recommended Routes:\n",
      "   RANK CANONICAL_ROUTE_PAIR  PROFIT_PER_FLIGHT  BREAKEVEN_ROUND_TRIP_FLIGHTS  \\\n",
      "0     1              JFK-LAX           31518.67                       2856.00   \n",
      "2     2              DCA-LGA           41194.65                       2185.00   \n",
      "4     3              CLT-GSP           80042.03                       1125.00   \n",
      "3     4              BOS-LGA           27574.06                       3264.00   \n",
      "1     5              DCA-ORD           39804.35                       2262.00   \n",
      "\n",
      "   TOTAL_PROFIT  ROUND_TRIP_FLIGHTS  AVG_DEP_DELAY  AVG_ARR_DELAY  \\\n",
      "0   99252298.23                3149          -1.51         -10.27   \n",
      "2   69124622.46                1678          -2.72          -5.26   \n",
      "4   61872487.00                 773          -1.28          -6.71   \n",
      "3   66398343.46                2408          -2.49          -8.00   \n",
      "1   73399227.77                1844          -2.85          -6.76   \n",
      "\n",
      "   COMPOSITE_SCORE  \n",
      "0            72.02  \n",
      "2            50.09  \n",
      "4            46.59  \n",
      "3            46.14  \n",
      "1            45.28  \n",
      "Saved DataFrame to: /Users/Rajz/Documents/Job Search/Capital One/airline_data_challenge_submission/output_steps/08_breakeven_for_recommended_routes.csv\n",
      "\n",
      "--- Final Data Quality Log Summary ---\n",
      "\n",
      "--- Data Quality Log Summary ---\n",
      "Run ID: 49ec5f94-94e7-4896-94ba-67fc53ec3155\n",
      "Total DQ metrics logged: 79\n",
      "Last 5 entries:\n",
      "              Timestamp                                 RunID     Phase  \\\n",
      "74  2025-05-13 21:41:12  49ec5f94-94e7-4896-94ba-67fc53ec3155  Analysis   \n",
      "75  2025-05-13 21:41:12  49ec5f94-94e7-4896-94ba-67fc53ec3155  Analysis   \n",
      "76  2025-05-13 21:41:12  49ec5f94-94e7-4896-94ba-67fc53ec3155  Analysis   \n",
      "77  2025-05-13 21:41:12  49ec5f94-94e7-4896-94ba-67fc53ec3155  Analysis   \n",
      "78  2025-05-13 21:41:12  49ec5f94-94e7-4896-94ba-67fc53ec3155  Analysis   \n",
      "\n",
      "                                     Step    TableName  \\\n",
      "74  Recommend 5 Routes (Advanced Scoring)  AdvancedRec   \n",
      "75  Recommend 5 Routes (Advanced Scoring)  AdvancedRec   \n",
      "76  Recommend 5 Routes (Advanced Scoring)  AdvancedRec   \n",
      "77  Recommend 5 Routes (Advanced Scoring)  AdvancedRec   \n",
      "78  Recommend 5 Routes (Advanced Scoring)  AdvancedRec   \n",
      "\n",
      "                          Metric                              Value  \\\n",
      "74             Normalized Metric                 NORM_AVG_OCCUPANCY   \n",
      "75             Normalized Metric               NORM_AVG_TOTAL_DELAY   \n",
      "76             Normalized Metric  NORM_BREAKEVEN_ROUND_TRIP_FLIGHTS   \n",
      "77    Composite Score Calculated                               True   \n",
      "78  Number of Routes Recommended                                  5   \n",
      "\n",
      "   Description  \n",
      "74              \n",
      "75              \n",
      "76              \n",
      "77              \n",
      "78              \n",
      "--- End of DQ Log Summary ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display breakeven details specifically for the 5 recommended routes\n",
    "if 'advanced_recommendations_df' in locals() and not advanced_recommendations_df.empty and \\\n",
    "   'breakeven_for_all_profitable_df' in locals() and not breakeven_for_all_profitable_df.empty:\n",
    "\n",
    "    print(\"\\n--- Q4: Breakeven Analysis for the 5 Recommended Routes ---\")\n",
    "    \n",
    "    # Filter the comprehensive breakeven data to only the recommended routes\n",
    "    recommended_route_pairs = advanced_recommendations_df['CANONICAL_ROUTE_PAIR'].tolist()\n",
    "    final_breakeven_display_df = breakeven_for_all_profitable_df[\n",
    "        breakeven_for_all_profitable_df['CANONICAL_ROUTE_PAIR'].isin(recommended_route_pairs)\n",
    "    ].copy()\n",
    "\n",
    "    # Merge with rank from recommendations for ordered display\n",
    "    final_breakeven_display_df = pd.merge(\n",
    "        final_breakeven_display_df,\n",
    "        advanced_recommendations_df[['CANONICAL_ROUTE_PAIR', 'RANK', 'COMPOSITE_SCORE']],\n",
    "        on='CANONICAL_ROUTE_PAIR',\n",
    "        how='left'\n",
    "    ).sort_values(by='RANK')\n",
    "\n",
    "\n",
    "    if not final_breakeven_display_df.empty:\n",
    "        print(f\"\\nBreakeven Analysis (Airplane Upfront Cost: ${config.AIRPLANE_UPFRONT_COST:,.0f} per route) for Recommended Routes:\")\n",
    "        cols_to_display_final_be = ['RANK', 'CANONICAL_ROUTE_PAIR', 'PROFIT_PER_FLIGHT', \n",
    "                                    'BREAKEVEN_ROUND_TRIP_FLIGHTS', 'TOTAL_PROFIT', \n",
    "                                    'ROUND_TRIP_FLIGHTS', 'AVG_DEP_DELAY', 'AVG_ARR_DELAY', 'COMPOSITE_SCORE']\n",
    "        cols_to_display_final_be = [col for col in cols_to_display_final_be if col in final_breakeven_display_df.columns]\n",
    "        print(final_breakeven_display_df[cols_to_display_final_be])\n",
    "        # Save intermediate output\n",
    "        step_name = \"08_breakeven_for_recommended_routes\"\n",
    "        file_name = f\"{step_name}.csv\"; output_file_path = os.path.join(config.STEP_OUTPUT_DIR, file_name)\n",
    "        df_to_save = final_breakeven_display_df.copy()\n",
    "        df_to_save.loc[:, config.BATCH_ID_COLUMN] = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3]\n",
    "        df_to_save.to_csv(output_file_path, index=False); print(f\"Saved DataFrame to: {output_file_path}\")\n",
    "\n",
    "    else:\n",
    "        print(\"Could not display breakeven analysis for recommended routes (e.g., if no routes were recommended or breakeven data missing).\")\n",
    "\n",
    "elif 'advanced_recommendations_df' in locals() and advanced_recommendations_df.empty:\n",
    "    print(\"No routes were recommended by the advanced scoring model. Skipping final breakeven display.\")\n",
    "else:\n",
    "    print(\"Prerequisite data for displaying breakeven of recommended routes is missing. Skipping.\")\n",
    "\n",
    "print(\"\\n--- Final Data Quality Log Summary ---\")\n",
    "if 'dq_utils' in globals() and hasattr(dq_utils, 'display_dq_summary'):\n",
    "    dq_utils.display_dq_summary()\n",
    "else:\n",
    "    print(\"dq_utils not available to display final summary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Data Quality Log Summary ---\n",
      "\n",
      "--- Data Quality Log Summary ---\n",
      "Run ID: 49ec5f94-94e7-4896-94ba-67fc53ec3155\n",
      "Total DQ metrics logged: 79\n",
      "Last 5 entries:\n",
      "              Timestamp                                 RunID     Phase  \\\n",
      "74  2025-05-13 21:41:12  49ec5f94-94e7-4896-94ba-67fc53ec3155  Analysis   \n",
      "75  2025-05-13 21:41:12  49ec5f94-94e7-4896-94ba-67fc53ec3155  Analysis   \n",
      "76  2025-05-13 21:41:12  49ec5f94-94e7-4896-94ba-67fc53ec3155  Analysis   \n",
      "77  2025-05-13 21:41:12  49ec5f94-94e7-4896-94ba-67fc53ec3155  Analysis   \n",
      "78  2025-05-13 21:41:12  49ec5f94-94e7-4896-94ba-67fc53ec3155  Analysis   \n",
      "\n",
      "                                     Step    TableName  \\\n",
      "74  Recommend 5 Routes (Advanced Scoring)  AdvancedRec   \n",
      "75  Recommend 5 Routes (Advanced Scoring)  AdvancedRec   \n",
      "76  Recommend 5 Routes (Advanced Scoring)  AdvancedRec   \n",
      "77  Recommend 5 Routes (Advanced Scoring)  AdvancedRec   \n",
      "78  Recommend 5 Routes (Advanced Scoring)  AdvancedRec   \n",
      "\n",
      "                          Metric                              Value  \\\n",
      "74             Normalized Metric                 NORM_AVG_OCCUPANCY   \n",
      "75             Normalized Metric               NORM_AVG_TOTAL_DELAY   \n",
      "76             Normalized Metric  NORM_BREAKEVEN_ROUND_TRIP_FLIGHTS   \n",
      "77    Composite Score Calculated                               True   \n",
      "78  Number of Routes Recommended                                  5   \n",
      "\n",
      "   Description  \n",
      "74              \n",
      "75              \n",
      "76              \n",
      "77              \n",
      "78              \n",
      "--- End of DQ Log Summary ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Final Data Quality Log Summary ---\")\n",
    "if 'dq_utils' in globals() and hasattr(dq_utils, 'display_dq_summary'):\n",
    "    dq_utils.display_dq_summary()\n",
    "else:\n",
    "    print(\"dq_utils not available to display final summary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Reporting & Strategic Outlook\n",
    "\n",
    "### Task 3.1: Key Performance Indicators (KPIs) - Simplified Core Set for Initial Launch\n",
    "\n",
    "**Listed in Tableau Presentation**\n",
    "\n",
    "### Task 3.2: \"What's Next?\" - Future Considerations\n",
    " - Outline future work, potential model enhancements, or further data product development ideas.\n",
    " - Include thoughts on enhancing the DQ monitoring framework.\n",
    "\n",
    " **\"What's Next?\" - Future Considerations & Enhancements:**\n",
    "\n",
    " While this analysis provides a strong foundation, several areas could be explored for future enhancements to deliver even better insights and a more robust data product:\n",
    "\n",
    " 1.  **Identify and Explore AI/ML Models for Better Prediction of Best Launch Routes**\n",
    "     * **Idea:** Investigate and prototype machine learning models (e.g., regression models to predict route profitability/demand, or Learning to Rank models if sufficient historical/proxy data could be acquired) using the existing and expanded feature set. This would move beyond the current weighted scoring.\n",
    "     * **Benefit:** Potentially uncovers more complex patterns and interactions between route characteristics that lead to success, leading to more data-driven and nuanced route selection. This could refine or challenge initial recommendations and improve the prediction of viability for entirely new, unproven routes.\n",
    "\n",
    " 2.  **Conduct In-depth Seasonality Analysis:**\n",
    "     * **Idea:** The current analysis disregards seasonal effects as per initial instructions. A crucial next step would be to acquire or model data spanning multiple quarters/years to analyze seasonal trends in demand, fare elasticity, and operational performance (e.g., weather-related delays) for key routes.\n",
    "     * **Benefit:** Allows for more accurate demand forecasting, optimized pricing strategies that adapt to peak and off-peak seasons, and better resource allocation (e.g., scheduling maintenance during lower demand periods). This directly improves the accuracy of profitability projections.\n",
    "\n",
    " 3.  **Develop Dynamic Demand & Pricing Models:**\n",
    "     * **Idea:** Move beyond the static 1Q2019 analysis by incorporating time-series forecasting for passenger demand on promising routes. Develop models to understand price elasticity and simulate the impact of different fare structures.\n",
    "     * **Benefit:** Enables more proactive revenue management, optimized pricing strategies considering seasonality (see next point) and booking patterns, and better capacity planning.\n",
    "     * **Fleet Optimization:** If different aircraft types are considered, model which aircraft is best suited for which route based on capacity, range, operating economics, and demand.\n",
    "\n",
    " 4.  **Customer-Centric Analytics:**\n",
    "     * **Idea:** Analyze passenger data (demographics, travel patterns, booking behavior) to identify distinct customer segments.\n",
    "     * **Benefit:** Moves beyond route-level profit to customer lifetime value, informing marketing, loyalty programs, and service improvements that truly resonate with valuable customer segments.\n",
    "\n",
    " 5.  **Improving the Data Quality (DQ) Monitoring Framework:**\n",
    "     * **Automated DQ Alerts & Anomaly Detection:** Implement systems that automatically flag significant DQ issues or anomalies in real-time or near real-time (e.g., sudden drop in data completeness for a key source, unusual spike in reported delays, fare data outside expected ranges).\n",
    "     * **DQ Root Cause Analysis Tools:** Enhance the DQ dashboard in Tableau (or other BI tools) with drill-down capabilities to more easily trace the origin of data quality problems.\n",
    "     * **Data Lineage Visualization:** Implement tools to visualize data lineage, showing how data flows from source systems through transformations to the final analytical tables and reports. This aids in understanding impact and tracing errors.\n",
    "     * **DQ Impact Quantification:** Develop methodologies to estimate the potential business impact of identified data quality issues (e.g., \"A 5% error in occupancy data could lead to an X% misstatement in projected revenue for route Y\").\n",
    "     * **Proactive DQ Rules & Validation:** Embed more complex validation rules directly into data ingestion and processing pipelines (e.g., using tools like Great Expectations) to catch issues earlier.\n",
    "     * **Feedback Loop for DQ Issues:** Formalize the process for data consumers to report DQ issues and for these issues to be tracked, prioritized, and resolved by data engineering or source system owners.\n",
    "\n",
    " These future steps would transform the current analytical product into a more dynamic, predictive, and strategically invaluable asset for the airline, supporting a wider range of operational and planning decisions.\n",
    "\n",
    " ### Task 3.3: Documentation & Submission Packaging\n",
    " - Ensure all Python scripts (`airline_scripts/*.py`) are well-commented with docstrings for functions and explanations for complex logic. (This is an ongoing task within the `.py` files themselves).\n",
    " - Ensure this Jupyter Notebook (`Airline_Route_Analysis.ipynb`) has clear markdown explanations for each step, interprets results, documents assumptions, and presents the overall narrative. (This is achieved through the markdown cells throughout this notebook).\n",
    " - Create/update `README.md` with a project overview, setup instructions (referencing `requirements.txt`), and guidance on how to run the notebook and view Tableau dashboards. (This is an external file).\n",
    " - Generate/finalize `requirements.txt` listing all Python dependencies. (This can be done using `pip freeze > requirements.txt` in the project's virtual environment).\n",
    " - Package all deliverables (notebook, scripts, reports, logs, README, requirements.txt, Tableau workbook) into a single ZIP file for submission. (This is the final external packaging step).\n",
    "\n",
    " ---\n",
    " ## End of Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
